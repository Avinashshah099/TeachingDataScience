{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3oxVq6vQ76r7"
   },
   "source": [
    "# Flight Search Chatbot\n",
    "\n",
    "Original Article: Build a Flight search chatbot from scratch using RASA Part 1 and 2 - Ashutosh Krishna, Medium \n",
    "\n",
    "Link: https://medium.com/datadriveninvestor/build-a-flight-search-chatbot-from-scratch-using-rasa-part-1-47370cf1e53b)\n",
    "\n",
    "Source: https://github.com/ashukrishna100/MMTchatbot/tree/master/MMT/MMT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kIFYA-Kp8aK4"
   },
   "source": [
    "**Objectives** To build a chatbot capable of fetching latest info about the flights between 2 cities. It uses MakeMyTrip.com's website.\n",
    "\n",
    "<img src=\"images/mmt.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rasa Stack\n",
    "\n",
    "- Lets you focus on improving the “Chatbot” part of your project \n",
    "- Default set up of Rasa works really well right out of the box for intent extraction and dialogue management\n",
    "- LOCAL models, no API calls for intent extraction and dialogue management, except if your business logic needs external calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture of chatbot\n",
    "\n",
    "<img src=\"images/domain.png\">\n",
    "\n",
    "\n",
    "- As soon as Rasa receives a message from the end user, it tries to predict or extract the “intent” and “entities” present in the message. This part is handled by Rasa NLU\n",
    "- Once the user’s intent is identified, the Rasa Stack performs an action called action_match_news to get the updates from the latest IPL match\n",
    "- Rasa then tries to predict what it should do next. This decision is taken considering multiple factors and is handled by Rasa Core\n",
    "- In this example, Rasa is showing the result of the most recent match to the user. It has also predicted the next action that our model should take – to check with the user whether the chatbot was able to solve his/her query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IVAF41hr8jU5"
   },
   "source": [
    "## Installations\n",
    "Official Documentation: https://rasa.com/docs/core/installation/\n",
    "* Python\n",
    "* Rasa Starter Pack\n",
    "* Spacy Language Model\n",
    "\n",
    "\n",
    "### Python\n",
    "* Install Anaconda 4.2.0 for Python 3.5 or Ananconda 5.2.0 for Python 3.6 \n",
    "* Windows Build tools: Make sure the Microsoft $VC++$ Compiler Visual Studio 2015 is installed, so python can compile any dependencies or https://visualstudio.microsoft.com/visual-cpp-build-tools/ Download the installer and select VC++ Build tools in the list.\n",
    "\n",
    "(My Note: on main page of Anaconda is https://www.anaconda.com/distribution/ you see Python 3.7, which is problematic, gives HTTP error while creating env. I had to delete 3.7 and get 3.6. Btw, this site does not mention which Anaconda installer has which Python version. WHY? thats the most crucial info. Anyway, I have given them here.)\n",
    "\n",
    "### Python Environment\n",
    "* By installing conda, you get base or the root environment, which is the default.\n",
    "* Practical tip: DO NOT install any packages in the root. ALWAYS create and env and install inside the new env.\n",
    "* Env is needed esepcially for fragile packages like Python (its treated as a package) and rasa.\n",
    "* So, **conda create -n rasa python=3.6** \n",
    "\n",
    "(My Note: Env management is again a sour point. It creates complete copy (deeeep) of python 3.6 and all other packages inside \"envs\" folder. Goes to 1.5 GB!! Can someone optimize it?)\n",
    "\n",
    "\n",
    "### MMT (Make My Trip) bot code (for reference)\n",
    "\n",
    "* Clone repo from  https://github.com/ashukrishna100/MMTchatbot/tree/master/MMT/MMT \n",
    "\n",
    "* Instalation requirements.txt file can be take from https://github.com/mohdsanadzakirizvi/iplbot.git\n",
    "\n",
    "* Additionally you will need to install Beautiful Soup\n",
    "\n",
    "<!---\n",
    "* Let’s take a look at the folder structure and the files that were created \n",
    "<img src=\"images/nlu.png\">\n",
    "* Install git, can git clone above package.\n",
    "-->\n",
    "\n",
    "* **WE WILL BE CODING IT FROM SCRATCH**\n",
    "* Run following commands:\n",
    "\n",
    "* **mkdir code; cd code;mkdir data**\n",
    "* **activate rasa**\n",
    "* **pip install -r iplbot_requirements.txt**\n",
    "* **pip install bs4**\n",
    "\n",
    "### Spacy Language Models\n",
    "* Open cmd in Administrator mode and activate the env\n",
    "* Download medium english by **python -m spacy download en_core_web_md** \n",
    "* Link with **python -m spacy link en_core_web_md en --force**\n",
    "\n",
    "\n",
    "(My Note: First command will show that linking is done, but it may not have happened actually. So, do next step anyway.)\n",
    "\n",
    "### Others\n",
    "* Install nb_conda_kernels to let Jupyter Notebook see the new env\n",
    "* We are not using API to access Make My Trip.com's data, but just the search results, like an usual user. Then Beautiful Soup library is used to parse the html results page\n",
    "\n",
    "<!---\n",
    "* Need Rasa Core SDK for custom actions **pip install rasa_core_sdk** and run it as **python -m rasa_core_sdk.endpoint --actions actions** where actions.py has all the custom actions\n",
    "* Install pygraphviz by **conda install -c alubbock pygraphviz**\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yHYeAA859JGq"
   },
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TSw6zFmk3iPu"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import logging, io, json, warnings\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import rasa_nlu\n",
    "import rasa_core\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEw5vhSq9gWa"
   },
   "source": [
    "## Rasa NLU: Extracting User Intent from a Message\n",
    "\n",
    "The first thing we want to do is figure out the intent of the user. What does he or she want to accomplish? Let’s utilize Rasa and build an NLU model to identify user intent and its related entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oDEAOmaI9o4a"
   },
   "source": [
    "### Preparing the NLU Training Data\n",
    "\n",
    "Training data for extracting the user intent.\n",
    "As you can see, the format of training data for ‘intent’ is quite simple in Rasa. You just have to:\n",
    "\n",
    "- Start the line with “## intent:intent_name”\n",
    "- Supply all the examples in the following lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RPxeQ1_14CjK",
    "outputId": "bfb5974f-f8ea-46b8-b8cb-9dd4479ed9cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'nlu_md' (str) to file 'data/nlu.md'.\n"
     ]
    }
   ],
   "source": [
    "nlu_md = \"\"\"\n",
    "## intent:flight\n",
    "-hey! I want latest flight schedule\n",
    "-can you provide me flight schedule\n",
    "-please provide latest flight info\n",
    "-is it possible to get latest flight information\n",
    "-flight schedule\n",
    "-flight information\n",
    "-flight info\n",
    "\n",
    "\n",
    "## intent:inform\n",
    "-[DEL](location)\n",
    "-[BOM](location)\n",
    "-[CCU](location)\n",
    "-[BLR](location)\n",
    "-[HYD](location)\n",
    "-[MAA](location)\n",
    "-[PNQ](location)\n",
    "-[IXC](location)\n",
    "-[09-01-2019](date)\n",
    "- I want for [09-02-2019](date)\n",
    "- i want to travel on [21-04-2019](date)\n",
    "\n",
    "\n",
    "## intent:affirmation\n",
    "-ok\n",
    "-yea\n",
    "-yes\n",
    "-definitely\n",
    "-yah\n",
    "\n",
    "## intent:deny\n",
    "-no\n",
    "-not yet\n",
    "-never\n",
    "-not now\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > data/nlu.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can include as many examples as you want for each intent. In fact, make sure to include slangs and short forms that you use while texting. The idea is to make the chatbot understand the way we type text. Feel free to refer to the complete version where I have given plenty of examples for each intent type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ceazcacn9veB"
   },
   "source": [
    "### Defining the NLU Model Configuration\n",
    "\n",
    "This file lets us create a text processing pipeline in Rasa. Luckily for us, Rasa comes with two default settings based on the amount of training data we have:\n",
    "- “spacy_sklearn” pipeline if you have less than 1000 training examples\n",
    "- “tensorflow_embedding” if you have a large amount of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dF60NWhR4ID6",
    "outputId": "92946645-94fc-4450-aa41-eca8895ff83c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'config' (str) to file 'config/config.yml'.\n"
     ]
    }
   ],
   "source": [
    "config = \"\"\"\n",
    "language: \"en\"\n",
    "\n",
    "pipeline:\n",
    "- name : \"nlp_spacy\"\n",
    "- name: \"tokenizer_whitespace\"\n",
    "- name: \"intent_entity_featurizer_regex\"\n",
    "- name: \"ner_crf\"\n",
    "- name: \"ner_synonyms\"\n",
    "- name: \"intent_featurizer_count_vectors\"\n",
    "- name: \"intent_classifier_tensorflow_embedding\"\n",
    "  intent_tokenization_flag: true\n",
    "  intent_split_symbol: \"+\" \n",
    "\"\"\" \n",
    "\n",
    "%store config > config/config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ieoWk91X9y8X"
   },
   "source": [
    "### Training the NLU Classifier Model\n",
    "\n",
    "On command line you can run following command:\n",
    "\n",
    "**python -m rasa_nlu.train -c config/config.yml --data data/nlu.md -o models --fixed_model_name nlu --project current --verbose**\n",
    "\n",
    "Or programmatically you can write code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "dp3AIHmS4L6x",
    "outputId": "8011c4f7-c789-4138-84d7-4710207615d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_nlu.training_data.loading:Training data format of data/nlu.md is md\n",
      "INFO:rasa_nlu.training_data.training_data:Training data stats: \n",
      "\t- intent examples: 27 (4 distinct intents)\n",
      "\t- Found intents: 'inform', 'deny', 'affirmation', 'flight'\n",
      "\t- entity examples: 11 (2 distinct entities)\n",
      "\t- found entities: 'location', 'date'\n",
      "\n",
      "INFO:rasa_nlu.utils.spacy_utils:Trying to load spacy model with name 'en'\n",
      "INFO:rasa_nlu.components:Added 'nlp_spacy' to component cache. Key 'nlp_spacy-en'.\n",
      "INFO:rasa_nlu.model:Starting to train component nlp_spacy\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component tokenizer_whitespace\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component intent_entity_featurizer_regex\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component ner_crf\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component ner_synonyms\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component intent_featurizer_count_vectors\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component intent_classifier_tensorflow_embedding\n",
      "INFO:rasa_nlu.classifiers.embedding_intent_classifier:Accuracy is updated every 10 epochs\n",
      "Epochs: 100%|████████████████████████████████████████████████| 300/300 [00:01<00:00, 175.15it/s, loss=0.085, acc=1.000]\n",
      "INFO:rasa_nlu.classifiers.embedding_intent_classifier:Finished training embedding classifier, loss=0.085, train accuracy=1.000\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Successfully saved model into 'C:\\YogeshKulkarni\\Training\\TeachingDataScience\\Jupyter\\bookingbot\\models\\nlu\\default\\chatter'\n"
     ]
    }
   ],
   "source": [
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu.config import RasaNLUModelConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "from rasa_nlu import config\n",
    "\n",
    "# loading the nlu training samples\n",
    "training_data = load_data(\"data/nlu.md\")\n",
    "\n",
    "# trainer to educate our pipeline\n",
    "trainer = Trainer(config.load(\"config/config.yml\"))\n",
    "\n",
    "# train the model!\n",
    "interpreter = trainer.train(training_data)\n",
    "\n",
    "# store it for future use\n",
    "model_directory = trainer.persist(\"./models/nlu\", fixed_model_name=\"chatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jrfp4xOS95ZZ"
   },
   "source": [
    "### Evaluating the NLU model on a random text (first way)\n",
    "\n",
    "Let’s test how good our model is performing by giving it a sample text that it hasn’t been trained on for extracting intent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "4UjzlqMV4N1k",
    "outputId": "37ea93e5-6a71-4e8e-d2b6-a45144d184ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"flight\",\n",
      "    \"confidence\": 0.9705340266227722\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"flight\",\n",
      "      \"confidence\": 0.9705340266227722\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirmation\",\n",
      "      \"confidence\": 0.0\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.0\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"inform\",\n",
      "      \"confidence\": 0.0\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"please provide latest flight info\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# A helper function for prettier output\n",
    "\n",
    "def pprint(o):   \n",
    "    print(json.dumps(o, indent=2))\n",
    "    \n",
    "pprint(interpreter.parse(\"please provide latest flight info\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only does our NLU model perform well on intent extraction, but it also ranks the other intents based on their confidence scores. This is a nifty little feature that can be really useful when the classifier is confused between multiple intents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the NLU model on a random text (2nd way)\n",
    "Let’s test how good our model is performing by giving it a sample text that it hasn’t been trained on for extracting intent. You can open an iPython/Python shell and follow the following steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_nlu.components:Added 'nlp_spacy' to component cache. Key 'nlp_spacy-en'.\n",
      "INFO:tensorflow:Restoring parameters from ./models/nlu/default/chatter\\intent_classifier_tensorflow_embedding.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'intent': {'name': 'flight', 'confidence': 0.9705340266227722},\n",
       " 'entities': [],\n",
       " 'intent_ranking': [{'name': 'flight', 'confidence': 0.9705340266227722},\n",
       "  {'name': 'affirmation', 'confidence': 0.0},\n",
       "  {'name': 'deny', 'confidence': 0.0},\n",
       "  {'name': 'inform', 'confidence': 0.0}],\n",
       " 'text': 'please provide latest flight info'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rasa_nlu.model import Interpreter\n",
    "nlu_model = Interpreter.load('./models/nlu/default/chatter')\n",
    "nlu_model.parse('please provide latest flight info')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OPlSd-As-Fz4"
   },
   "source": [
    "### Evaluating the NLU model on a test data\n",
    "(Here we are using the data at hand i.e nlu.md but it isr recommended to use unseen data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1483
    },
    "colab_type": "code",
    "id": "FmRCylbT4jyw",
    "outputId": "fd1bfd57-ebb3-4541-d3b3-b4cbba781164"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_nlu.components:Added 'nlp_spacy' to component cache. Key 'nlp_spacy-en'.\n",
      "INFO:tensorflow:Restoring parameters from C:\\YogeshKulkarni\\Training\\TeachingDataScience\\Jupyter\\bookingbot\\./models/nlu\\default\\chatter\\intent_classifier_tensorflow_embedding.ckpt\n",
      "INFO:rasa_nlu.training_data.loading:Training data format of data/nlu.md is md\n",
      "INFO:rasa_nlu.training_data.training_data:Training data stats: \n",
      "\t- intent examples: 27 (4 distinct intents)\n",
      "\t- Found intents: 'inform', 'deny', 'affirmation', 'flight'\n",
      "\t- entity examples: 11 (2 distinct entities)\n",
      "\t- found entities: 'location', 'date'\n",
      "\n",
      "INFO:rasa_nlu.evaluate:Intent evaluation results:\n",
      "INFO:rasa_nlu.evaluate:Intent Evaluation: Only considering those 27 examples that have a defined intent out of 27 examples\n",
      "INFO:rasa_nlu.evaluate:F1-Score:  1.0\n",
      "INFO:rasa_nlu.evaluate:Precision: 1.0\n",
      "INFO:rasa_nlu.evaluate:Accuracy:  1.0\n",
      "INFO:rasa_nlu.evaluate:Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " affirmation       1.00      1.00      1.00         5\n",
      "        deny       1.00      1.00      1.00         4\n",
      "      flight       1.00      1.00      1.00         7\n",
      "      inform       1.00      1.00      1.00        11\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        27\n",
      "   macro avg       1.00      1.00      1.00        27\n",
      "weighted avg       1.00      1.00      1.00        27\n",
      "\n",
      "INFO:rasa_nlu.evaluate:Your model made no errors\n",
      "INFO:rasa_nlu.evaluate:Entity evaluation results:\n",
      "INFO:rasa_nlu.evaluate:Evaluation for entity extractor: ner_crf \n",
      "INFO:rasa_nlu.evaluate:F1-Score:  1.0\n",
      "INFO:rasa_nlu.evaluate:Precision: 1.0\n",
      "INFO:rasa_nlu.evaluate:Accuracy:  1.0\n",
      "INFO:rasa_nlu.evaluate:Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        date       1.00      1.00      1.00         3\n",
      "    location       1.00      1.00      1.00         8\n",
      "   no_entity       1.00      1.00      1.00        50\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        61\n",
      "   macro avg       1.00      1.00      1.00        61\n",
      "weighted avg       1.00      1.00      1.00        61\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'intent_evaluation': {'predictions': [{'text': 'hey! I want latest flight schedule',\n",
       "    'intent': 'flight',\n",
       "    'predicted': 'flight',\n",
       "    'confidence': 0.9746279716491699},\n",
       "   {'text': 'can you provide me flight schedule',\n",
       "    'intent': 'flight',\n",
       "    'predicted': 'flight',\n",
       "    'confidence': 0.9729326963424683},\n",
       "   {'text': 'please provide latest flight info',\n",
       "    'intent': 'flight',\n",
       "    'predicted': 'flight',\n",
       "    'confidence': 0.9705340266227722},\n",
       "   {'text': 'is it possible to get latest flight information',\n",
       "    'intent': 'flight',\n",
       "    'predicted': 'flight',\n",
       "    'confidence': 0.9685079455375671},\n",
       "   {'text': 'flight schedule',\n",
       "    'intent': 'flight',\n",
       "    'predicted': 'flight',\n",
       "    'confidence': 0.9815781116485596},\n",
       "   {'text': 'flight information',\n",
       "    'intent': 'flight',\n",
       "    'predicted': 'flight',\n",
       "    'confidence': 0.9756697416305542},\n",
       "   {'text': 'flight info',\n",
       "    'intent': 'flight',\n",
       "    'predicted': 'flight',\n",
       "    'confidence': 0.9651832580566406},\n",
       "   {'text': 'DEL',\n",
       "    'intent': 'inform',\n",
       "    'predicted': 'inform',\n",
       "    'confidence': 0.959945797920227},\n",
       "   {'text': 'BOM',\n",
       "    'intent': 'inform',\n",
       "    'predicted': 'inform',\n",
       "    'confidence': 0.9737045168876648},\n",
       "   {'text': 'CCU',\n",
       "    'intent': 'inform',\n",
       "    'predicted': 'inform',\n",
       "    'confidence': 0.9703497290611267},\n",
       "   {'text': 'BLR',\n",
       "    'intent': 'inform',\n",
       "    'predicted': 'inform',\n",
       "    'confidence': 0.9581210613250732},\n",
       "   {'text': 'HYD',\n",
       "    'intent': 'inform',\n",
       "    'predicted': 'inform',\n",
       "    'confidence': 0.9736834764480591},\n",
       "   {'text': 'MAA',\n",
       "    'intent': 'inform',\n",
       "    'predicted': 'inform',\n",
       "    'confidence': 0.9720292091369629},\n",
       "   {'text': 'PNQ',\n",
       "    'intent': 'inform',\n",
       "    'predicted': 'inform',\n",
       "    'confidence': 0.955339789390564},\n",
       "   {'text': 'IXC',\n",
       "    'intent': 'inform',\n",
       "    'predicted': 'inform',\n",
       "    'confidence': 0.9766335487365723},\n",
       "   {'text': '09-01-2019',\n",
       "    'intent': 'inform',\n",
       "    'predicted': 'inform',\n",
       "    'confidence': 0.9715350866317749},\n",
       "   {'text': 'I want for 09-02-2019',\n",
       "    'intent': 'inform',\n",
       "    'predicted': 'inform',\n",
       "    'confidence': 0.9648852348327637},\n",
       "   {'text': 'i want to travel on 21-04-2019',\n",
       "    'intent': 'inform',\n",
       "    'predicted': 'inform',\n",
       "    'confidence': 0.9686853289604187},\n",
       "   {'text': 'ok',\n",
       "    'intent': 'affirmation',\n",
       "    'predicted': 'affirmation',\n",
       "    'confidence': 0.9464086890220642},\n",
       "   {'text': 'yea',\n",
       "    'intent': 'affirmation',\n",
       "    'predicted': 'affirmation',\n",
       "    'confidence': 0.9439424276351929},\n",
       "   {'text': 'yes',\n",
       "    'intent': 'affirmation',\n",
       "    'predicted': 'affirmation',\n",
       "    'confidence': 0.9530383348464966},\n",
       "   {'text': 'definitely',\n",
       "    'intent': 'affirmation',\n",
       "    'predicted': 'affirmation',\n",
       "    'confidence': 0.9438452124595642},\n",
       "   {'text': 'yah',\n",
       "    'intent': 'affirmation',\n",
       "    'predicted': 'affirmation',\n",
       "    'confidence': 0.9302364587783813},\n",
       "   {'text': 'no',\n",
       "    'intent': 'deny',\n",
       "    'predicted': 'deny',\n",
       "    'confidence': 0.9519248604774475},\n",
       "   {'text': 'not yet',\n",
       "    'intent': 'deny',\n",
       "    'predicted': 'deny',\n",
       "    'confidence': 0.9594603776931763},\n",
       "   {'text': 'never',\n",
       "    'intent': 'deny',\n",
       "    'predicted': 'deny',\n",
       "    'confidence': 0.959218442440033},\n",
       "   {'text': 'not now',\n",
       "    'intent': 'deny',\n",
       "    'predicted': 'deny',\n",
       "    'confidence': 0.9674083590507507}],\n",
       "  'report': '              precision    recall  f1-score   support\\n\\n affirmation       1.00      1.00      1.00         5\\n        deny       1.00      1.00      1.00         4\\n      flight       1.00      1.00      1.00         7\\n      inform       1.00      1.00      1.00        11\\n\\n   micro avg       1.00      1.00      1.00        27\\n   macro avg       1.00      1.00      1.00        27\\nweighted avg       1.00      1.00      1.00        27\\n',\n",
       "  'precision': 1.0,\n",
       "  'f1_score': 1.0,\n",
       "  'accuracy': 1.0},\n",
       " 'entity_evaluation': {'ner_crf': {'report': '              precision    recall  f1-score   support\\n\\n        date       1.00      1.00      1.00         3\\n    location       1.00      1.00      1.00         8\\n   no_entity       1.00      1.00      1.00        50\\n\\n   micro avg       1.00      1.00      1.00        61\\n   macro avg       1.00      1.00      1.00        61\\nweighted avg       1.00      1.00      1.00        61\\n',\n",
       "   'precision': 1.0,\n",
       "   'f1_score': 1.0,\n",
       "   'accuracy': 1.0}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rasa_nlu.evaluate import run_evaluation\n",
    "\n",
    "run_evaluation(\"data/nlu.md\", model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Av3R2GZZ-WJO"
   },
   "source": [
    "## Rasa Core: Making Interactive Conversations\n",
    "\n",
    "One of the most important aspects of a chatbot application is its ability to be interactive. \n",
    "\n",
    "### Designing the conversational flow\n",
    "\n",
    "Think of the simplest conversation our chatbot can have with a user. What would be the flow of such a conversation?\n",
    "\n",
    "---\n",
    "Me: Hi\n",
    "\n",
    "Iplbot: Hey! How may I help you?\n",
    "\n",
    "Me: Please provide me latest flight info\n",
    "\n",
    "bot: Please provide your origin airport code?\n",
    "\n",
    "Me: PNQ\n",
    "\n",
    "bot: Please provide your destination airport code?\n",
    "\n",
    "Me: BLR\n",
    "\n",
    "bot: What is the date of your travel (in dd-mm-yyyy)?\n",
    "\n",
    "Me: 27-05-2019\n",
    "\n",
    "bot: Here is the list of carriers with their fare\n",
    "\n",
    "Jet Airways : Rs. 8,220\n",
    "Vistara : Rs. 14,570\n",
    "IndiGo: Rs. 5,932\n",
    "\n",
    "bot: Do you want to make another inquiry?\n",
    "\n",
    "Me: no\n",
    "\n",
    "bot: Thanks for contacting us. Have a good day!\n",
    "\n",
    "---\n",
    "Let’s see how we can teach a simple conversation like that to Rasa:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## news path 1\n",
    "* greet\n",
    "  - utter_greet\n",
    "* current_flight_info\n",
    "  - action_flight_info\n",
    "  - utter_did_that_help\n",
    "* affirm or thanks\n",
    "  - utter_gratitude\n",
    "* goodbye\n",
    "  - utter_goodbye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general format is:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## news path 1           <--- story name for debugging purposes\n",
    "* greet                  <--- intent detected from the user\n",
    "  - utter_greet          <--- what action the bot should take\n",
    "* current_flight_info    <--- the following intent in the conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is called a user story path. I have provided a few stories in the data/stories.md file for your reference. This is the training data for Rasa Core."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BKZ63AuS-ZPV"
   },
   "source": [
    "### Writing  Stories\n",
    "\n",
    "The way it works is:\n",
    "\n",
    "- Give some examples of sample story paths that the user is expected to follow\n",
    "- Rasa Core combines them randomly to create more complex user paths\n",
    "- It then builds a probabilistic model out of that. This model is used to predict the next action Rasa should take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W3q1XJ5O4orY",
    "outputId": "a82511c7-b7e5-462c-c5c2-35df3cabd39a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'stories_md' (str) to file 'data/stories.md'.\n"
     ]
    }
   ],
   "source": [
    "stories_md = \"\"\"\n",
    "## fallback\n",
    "- utter_unclear\n",
    "\n",
    "\n",
    "## Story 1\n",
    "* flight\n",
    "    - utter_boarding\n",
    "* inform{\"location\": \"BOM\"}\n",
    "    - action_save_origin\n",
    "    - slot{\"from\": \"BOM\"}\n",
    "    - utter_destination\n",
    "* inform{\"location\": \"DEL\"}\n",
    "    - action_save_destination\n",
    "    - slot{\"to\": \"DEL\"}\n",
    "    - utter_date\n",
    "* inform{\"date\": \"20-01-2019\"}\n",
    "    - action_save_date\n",
    "    - slot{\"date\": \"20-01-2019\"}\n",
    "    - utter_confirm\n",
    "* affirmation\n",
    "    - action_get_flight\n",
    "\t- utter_check_another_one\n",
    "* deny\n",
    "\t- utter_thanks\n",
    "\t- action_restart\n",
    "\n",
    "## Stry 2-multiple steps\n",
    "* flight\n",
    "    - utter_boarding\n",
    "* inform{\"location\": \"PNQ\"}\n",
    "    - action_save_origin\n",
    "    - slot{\"from\": \"PNQ\"}\n",
    "    - utter_destination\n",
    "* inform{\"location\": \"BLR\"}\n",
    "    - action_save_destination\n",
    "    - slot{\"to\": \"BLR\"}\n",
    "    - utter_date\n",
    "* inform{\"date\": \"03-02-2019\"}\n",
    "    - slot{\"date\": \"03-02-2019\"}\n",
    "    - action_save_date\n",
    "    - slot{\"date\": \"03-02-2019\"}\n",
    "    - utter_confirm\n",
    "* affirmation\n",
    "    - action_get_flight\n",
    "    - utter_check_another_one\n",
    "* affirmation\n",
    "\t- action_slot_reset\n",
    "\t- reset_slots\n",
    "    - utter_boarding\n",
    "* inform{\"location\": \"BOM\"}\n",
    "    - action_save_origin\n",
    "    - slot{\"from\": \"BOM\"}\n",
    "    - utter_destination\n",
    "* inform{\"location\": \"DEL\"}\n",
    "    - action_save_destination\n",
    "    - slot{\"to\": \"DEL\"}\n",
    "    - utter_date\n",
    "* inform{\"date\": \"10-02-2019\"}\n",
    "    - slot{\"date\": \"10-02-2019\"}\n",
    "    - action_save_date\n",
    "    - slot{\"date\": \"10-02-2019\"}\n",
    "    - utter_confirm\n",
    "* affirmation\n",
    "    - action_get_flight\n",
    "    - utter_check_another_one\n",
    "* deny\n",
    "    - utter_thanks\n",
    "    - action_restart\n",
    "\"\"\"\n",
    "\n",
    "%store stories_md > data/stories.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, generate a similar graph for your stories using the following command:\n",
    "\n",
    "**python -m rasa_core.visualize -d domain.yml -s data/stories.md -o graph.html**\n",
    "\n",
    "This is very helpful when debugging the conversational flow of the chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LnD9v_CX-ePm"
   },
   "source": [
    "### Defining the Domain\n",
    "\n",
    "The domain is the world of your chatbot. It contains everything the chatbot should know, including:\n",
    "\n",
    "- All the actions it is capable of doing\n",
    "- The intents it should understand\n",
    "- The template of all the utterances it should tell the user, and much more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3SzQq1oy5U9T",
    "outputId": "4fde8c0d-9672-457c-cacc-0e86d3ca5c80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'domain_yml' (str) to file 'config/domain.yml'.\n"
     ]
    }
   ],
   "source": [
    "domain_yml = \"\"\"\n",
    "intents:\n",
    "- ticket\n",
    "- inform\n",
    "- affirmation\n",
    "- deny\n",
    "\n",
    "entities:\n",
    "- location \n",
    "- date\n",
    "\n",
    "slots:\n",
    "   from:\n",
    "            type: text\n",
    "   to:\n",
    "            type: text\n",
    "   date:\n",
    "            type: text\n",
    "\n",
    "actions:\n",
    "- utter_boarding\n",
    "- utter_destination\n",
    "- utter_date\n",
    "- utter_confirm\n",
    "- utter_check_another_one\n",
    "- utter_thanks\n",
    "- utter_unclear\n",
    "- action_save_origin\n",
    "- action_save_destination\n",
    "- action_save_date\n",
    "- action_get_flight\n",
    "- action_slot_reset\n",
    "templates:\n",
    "  \n",
    "  utter_boarding:\n",
    "  - text: \"We'll help you find the latest flight schedule. First, please provide your origin airport code?\"\n",
    "  \n",
    "  utter_destination:\n",
    "  - text: \"And the destination airport code?\"\n",
    "  \n",
    "  utter_date:\n",
    "  - text: \"What is the date for your travel(in dd-mm-yyyy)?\"\n",
    "  \n",
    "  utter_confirm:\n",
    "  - text: \"I will be making inquiry for flight from {from} to {to} on {date}. Is that correct?\"\n",
    "  \n",
    "  utter_check_another_one:\n",
    "  - text: \"Do you want to make another inquiry?\"\n",
    "  \n",
    "  utter_thanks:\n",
    "  - text: \"Thanks for contacting us. Have a good day!\"\n",
    "  \n",
    "  utter_unclear:\n",
    "  - text: \"I am not sure what you are aiming for.Kindly try it again\"\n",
    "\"\"\"\n",
    "\n",
    "%store domain_yml > config/domain.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Policies\n",
    "\n",
    "Rasa Core generates the training data for the conversational part using the stories we provide. It also lets you define a set of policies to use when deciding the next action of the chatbot. These policies are defined in the policies.yml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'policies_yml' (str) to file 'config/policies.yml'.\n"
     ]
    }
   ],
   "source": [
    "policies_yml = \"\"\"\n",
    "policies:\n",
    "  - name: KerasPolicy\n",
    "    epochs: 100\n",
    "    max_history: 5\n",
    "  - name: FallbackPolicy\n",
    "    fallback_action_name: 'action_default_fallback'\n",
    "  - name: MemoizationPolicy\n",
    "    max_history: 5\n",
    "\"\"\"\n",
    "\n",
    "%store policies_yml > config/policies.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- KerasPolicy uses a neural network implemented in Keras to select the next action. The default architecture is based on an LSTM (Long Short Term Memory) model\n",
    "- MemoizationPolicy memorizes the conversations in your training data. It predicts the next action with confidence 1.0 if this exact conversation exists in the training data, otherwise, it predicts ‘None’ with confidence 0.0\n",
    "- FallbackPolicy invokes a fallback action if the intent recognition has confidence below nlu_threshold or if none of the dialogue policies predict action with confidence higher than core_threshold\n",
    "- One important hyperparameter for Rasa Core policies is the max_history. This controls how much dialogue history the model looks at to decide which action to take next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ROL3AYs5-iCg"
   },
   "source": [
    "###  Custom Actions\n",
    "\n",
    "Using Make My Trip search results for fetching flight related info. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7SbmLMJa5X0E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'actions_py' (str) to file 'actions.py'.\n"
     ]
    }
   ],
   "source": [
    "actions_py=\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "from rasa_core.domain import Domain\n",
    "from rasa_core.trackers import EventVerbosity\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from rasa_core_sdk import Action\n",
    "from rasa_core_sdk.events import SlotSet\n",
    "from rasa_core_sdk.events import UserUtteranceReverted\n",
    "from rasa_core_sdk.events import AllSlotsReset\n",
    "from rasa_core_sdk.events import Restarted\n",
    "\n",
    "\n",
    "\t\t \n",
    "class SaveOrigin(Action):\n",
    "\tdef name(self):\n",
    "\t\treturn 'action_save_origin'\n",
    "\t\t\n",
    "\tdef run(self, dispatcher, tracker, domain):\n",
    "\t\torig = next(tracker.get_latest_entity_values(\"location\"), None)\n",
    "\t\tif not orig:\n",
    "\t\t\tdispatcher.utter_message(\"Please enter a valid airport code\")\n",
    "\t\t\treturn [UserUtteranceReverted()]\n",
    "\t\treturn [SlotSet('from',orig)]\n",
    "\t\n",
    "\n",
    "\n",
    "class SaveDestination(Action):\n",
    "\tdef name(self):\n",
    "\t\treturn 'action_save_destination'\n",
    "\t\t\n",
    "\tdef run(self, dispatcher, tracker, domain):\n",
    "\t\tdest = next(tracker.get_latest_entity_values(\"location\"), None)\n",
    "\t\tif not dest:\n",
    "\t\t\tdispatcher.utter_message(\"Please enter a valid airport code\")\n",
    "\t\t\treturn [UserUtteranceReverted()]\n",
    "\t\treturn [SlotSet('to',dest)]\n",
    "\t\t\n",
    "\t\t\n",
    "class SaveDate(Action):\n",
    "\tdef name(self):\n",
    "\t\treturn 'action_save_date'\n",
    "\t\t\n",
    "\tdef run(self, dispatcher, tracker, domain):\n",
    "\t\tinp = next(tracker.get_latest_entity_values(\"date\"), None)\n",
    "\t\tif not inp:\n",
    "\t\t\tdispatcher.utter_message(\"Please enter a valid date\")\n",
    "\t\t\treturn [UserUtteranceReverted()]\n",
    "\t\treturn [SlotSet('date',inp)]\n",
    "\t\t\n",
    "class ActionSlotReset(Action): \t\n",
    "    def name(self): \t\t\n",
    "        return 'action_slot_reset' \t\n",
    "    def run(self, dispatcher, tracker, domain): \t\t\n",
    "        return[AllSlotsReset()]\n",
    "\t\t\n",
    "\n",
    "\t\t\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import re\n",
    "\n",
    "\n",
    "class getFlightStatus(Action):\n",
    "\tdef name(self):\n",
    "\t\treturn 'action_get_flight'\n",
    "\tdef run(self, dispatcher, tracker, domain):\n",
    "\t\torig=tracker.get_slot('from')\n",
    "\t\tdest=tracker.get_slot('to')\n",
    "\t\tdat=tracker.get_slot('date')\n",
    "\t\tquote_page = \"https://flights.makemytrip.com/makemytrip/search/O/O/E/1/0/0/S/V0/{}_{}_{}?contains=false&remove=\"\n",
    "\t\tpage=urllib.request.urlopen(quote_page.format(orig,dest,dat))\n",
    "\t\tsoup = BeautifulSoup(page, 'html.parser')\n",
    "\t\tlist1=[]\n",
    "\t\tmessage=soup.find_all('label',attrs={'class':'flL mtop5 mleft3 vallabel'})\n",
    "\t\tdispatcher.utter_message(\"Here is the list of carriers with their fare\")\n",
    "\t\tfor a in message:\n",
    "\t\t\tlist1.append(a.text)\t\n",
    "\t\tmessage1=soup.find_all('span',attrs={'class':'flR'})\n",
    "\t\tlist2=[]\n",
    "\t\tfor b in message1:\n",
    "\t\t\tif \"Rs.\" in b.text:\n",
    "\t\t\t\tlist2.append(re.sub('\\s+', '', b.text))\n",
    "\t\tfor i in range(len(list1)):\n",
    "\t\t\tdispatcher.utter_message(list1[i]+\" : \"+list2[i])\n",
    "\t\treturn []\n",
    "\"\"\"\n",
    "%store actions_py > actions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need endpoints yml to execute the actions server.\n",
    "\n",
    "Note: If you have external API call, like REST, need to have \"webhook\" word at the end, else nothing.\n",
    "\n",
    "My own query on this topic: https://forum.rasa.com/t/rasa-core-sdk-not-working/9228"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'endpoints_yml' (str) to file 'endpoints.yml'.\n"
     ]
    }
   ],
   "source": [
    "endpoints_yml = \"\"\"\n",
    "#action_endpoint:\n",
    "#  url: \"http://localhost:5055/webhook\"\n",
    "  \n",
    "action_endpoint:\n",
    "  url: http://localhost:5055/webhook\n",
    "\n",
    "#nlg:\n",
    "#  url: http://localhost:5056/nlg\n",
    "\n",
    "core_endpoint:\n",
    "  url: http://localhost:5005\n",
    "\"\"\"\n",
    "%store endpoints_yml > endpoints.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a separate shell (cmd for Windows):\n",
    "- **activate rasa**\n",
    "- come to directory where actions.py is and then run\n",
    "- **python -m rasa_core_sdk.endpoint --actions actions**\n",
    "\n",
    "This way, custom action server starts ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# python = sys.executable\n",
    "# !{python} -m rasa_core_sdk.endpoint --actions actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M-jn1g_k-o-m"
   },
   "source": [
    "###  Visualising the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1090
    },
    "colab_type": "code",
    "id": "O1gYRXe15amU",
    "outputId": "9c0838e3-56c1-4eeb-a879-cc09619269d3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:rasa_core.training.dsl:Found unknown intent 'flight' on line 7. Please, make sure that all intents are listed in your domain yaml.\n",
      "WARNING:rasa_core.training.dsl:Found unknown intent 'flight' on line 29. Please, make sure that all intents are listed in your domain yaml.\n",
      "Processed Story Blocks: 100%|█████| 3/3 [00:00<00:00, 374.98it/s, # trackers=1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from IPython.display import Image, display\n",
    "from rasa_core.agent import Agent\n",
    "%matplotlib inline\n",
    "\n",
    "agent = Agent('config/domain.yml')\n",
    "agent.visualize(\"data/stories.md\", \"images/story_graph.png\", max_history=2)\n",
    "i = Image(filename=\"images/story_graph.png\")\n",
    "display(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See image as\n",
    "\n",
    "<img src=\"images/story_graph.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCdKD3l7-ua8"
   },
   "source": [
    "### Training a Dialogue Model\n",
    "\n",
    "You can train the model using the following command:\n",
    "\n",
    "**python -m rasa_core.train -d config/domain.yml -s data/stories.md -o models/current/dialogue -c config/policies.yml**\n",
    "\n",
    "Or do it programmatically as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7364
    },
    "colab_type": "code",
    "id": "4D7R-FRO5dxz",
    "outputId": "727adf2a-fa4b-4158-df94-30ad472f62f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:rasa_core.training.dsl:Found unknown intent 'flight' on line 7. Please, make sure that all intents are listed in your domain yaml.\n",
      "WARNING:rasa_core.training.dsl:Found unknown intent 'flight' on line 29. Please, make sure that all intents are listed in your domain yaml.\n",
      "Processed Story Blocks: 100%|█████| 3/3 [00:00<00:00, 428.54it/s, # trackers=1]\n",
      "Processed Story Blocks: 100%|█████| 3/3 [00:00<00:00, 374.97it/s, # trackers=2]\n",
      "Processed Story Blocks: 100%|█████| 3/3 [00:00<00:00, 230.76it/s, # trackers=4]\n",
      "Processed Story Blocks: 100%|█████| 3/3 [00:00<00:00, 199.99it/s, # trackers=6]\n",
      "Processed actions: 37it [00:00, 739.96it/s, # examples=37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (None, 5, 28)             0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                7808      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 19)                627       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 19)                0         \n",
      "=================================================================\n",
      "Total params: 8,435\n",
      "Trainable params: 8,435\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_core.policies.keras_policy:Fitting model with 60 total samples and a validation split of 0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.9537 - acc: 0.125 - 1s 17ms/step - loss: 2.9407 - acc: 0.1333\n",
      "Epoch 2/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.9007 - acc: 0.156 - 0s 327us/step - loss: 2.8897 - acc: 0.1833\n",
      "Epoch 3/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.8392 - acc: 0.250 - 0s 883us/step - loss: 2.8372 - acc: 0.2333\n",
      "Epoch 4/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.8130 - acc: 0.406 - 0s 333us/step - loss: 2.8147 - acc: 0.4167\n",
      "Epoch 5/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.7859 - acc: 0.406 - 0s 267us/step - loss: 2.7831 - acc: 0.4167\n",
      "Epoch 6/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.7482 - acc: 0.343 - 0s 250us/step - loss: 2.7495 - acc: 0.3667\n",
      "Epoch 7/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.6937 - acc: 0.343 - 0s 233us/step - loss: 2.7133 - acc: 0.3833\n",
      "Epoch 8/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.7121 - acc: 0.343 - 0s 300us/step - loss: 2.6861 - acc: 0.3667\n",
      "Epoch 9/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.6491 - acc: 0.375 - 0s 483us/step - loss: 2.6509 - acc: 0.3833\n",
      "Epoch 10/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.6374 - acc: 0.437 - 0s 367us/step - loss: 2.6427 - acc: 0.4167\n",
      "Epoch 11/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.5668 - acc: 0.437 - 0s 350us/step - loss: 2.5801 - acc: 0.4167\n",
      "Epoch 12/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.5458 - acc: 0.437 - 0s 400us/step - loss: 2.5552 - acc: 0.4167\n",
      "Epoch 13/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.4919 - acc: 0.437 - 0s 317us/step - loss: 2.5200 - acc: 0.4167\n",
      "Epoch 14/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.4685 - acc: 0.437 - 0s 400us/step - loss: 2.5089 - acc: 0.4167\n",
      "Epoch 15/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.4388 - acc: 0.437 - 0s 317us/step - loss: 2.4483 - acc: 0.4167\n",
      "Epoch 16/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.3891 - acc: 0.437 - 0s 417us/step - loss: 2.4380 - acc: 0.4167\n",
      "Epoch 17/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.3819 - acc: 0.437 - 0s 500us/step - loss: 2.4193 - acc: 0.4167\n",
      "Epoch 18/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.3324 - acc: 0.437 - 0s 483us/step - loss: 2.3807 - acc: 0.4167\n",
      "Epoch 19/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.3457 - acc: 0.437 - 0s 333us/step - loss: 2.3889 - acc: 0.4167\n",
      "Epoch 20/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.3231 - acc: 0.437 - 0s 550us/step - loss: 2.3530 - acc: 0.4167\n",
      "Epoch 21/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.2701 - acc: 0.437 - 0s 333us/step - loss: 2.3152 - acc: 0.4167\n",
      "Epoch 22/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.2740 - acc: 0.437 - 0s 383us/step - loss: 2.3348 - acc: 0.4167\n",
      "Epoch 23/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.2345 - acc: 0.437 - 0s 417us/step - loss: 2.2875 - acc: 0.4167\n",
      "Epoch 24/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.2228 - acc: 0.437 - 0s 417us/step - loss: 2.2904 - acc: 0.4167\n",
      "Epoch 25/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.1753 - acc: 0.437 - 0s 283us/step - loss: 2.2557 - acc: 0.4167\n",
      "Epoch 26/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.1792 - acc: 0.437 - 0s 333us/step - loss: 2.2417 - acc: 0.4167\n",
      "Epoch 27/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.1647 - acc: 0.437 - 0s 300us/step - loss: 2.2467 - acc: 0.4167\n",
      "Epoch 28/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.1517 - acc: 0.437 - 0s 283us/step - loss: 2.2210 - acc: 0.4167\n",
      "Epoch 29/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.1163 - acc: 0.437 - 0s 267us/step - loss: 2.1949 - acc: 0.4167\n",
      "Epoch 30/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.0727 - acc: 0.437 - 0s 267us/step - loss: 2.1710 - acc: 0.4167\n",
      "Epoch 31/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.0924 - acc: 0.437 - 0s 317us/step - loss: 2.1882 - acc: 0.4167\n",
      "Epoch 32/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.0552 - acc: 0.437 - 0s 317us/step - loss: 2.1330 - acc: 0.4167\n",
      "Epoch 33/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.0555 - acc: 0.437 - 0s 300us/step - loss: 2.1506 - acc: 0.4167\n",
      "Epoch 34/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.0476 - acc: 0.437 - 0s 333us/step - loss: 2.1462 - acc: 0.4167\n",
      "Epoch 35/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.9967 - acc: 0.437 - 0s 317us/step - loss: 2.0882 - acc: 0.4167\n",
      "Epoch 36/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 2.0157 - acc: 0.437 - 0s 283us/step - loss: 2.1095 - acc: 0.4167\n",
      "Epoch 37/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.9842 - acc: 0.437 - 0s 333us/step - loss: 2.0741 - acc: 0.4167\n",
      "Epoch 38/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.9534 - acc: 0.437 - 0s 300us/step - loss: 2.0519 - acc: 0.4167\n",
      "Epoch 39/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.9353 - acc: 0.437 - 0s 250us/step - loss: 2.0552 - acc: 0.4167\n",
      "Epoch 40/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.9434 - acc: 0.437 - 0s 317us/step - loss: 2.0376 - acc: 0.4167\n",
      "Epoch 41/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.9271 - acc: 0.437 - 0s 317us/step - loss: 2.0093 - acc: 0.4167\n",
      "Epoch 42/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.8920 - acc: 0.437 - 0s 317us/step - loss: 1.9907 - acc: 0.4167\n",
      "Epoch 43/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.8680 - acc: 0.437 - 0s 300us/step - loss: 1.9957 - acc: 0.4167\n",
      "Epoch 44/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.8582 - acc: 0.437 - 0s 267us/step - loss: 1.9759 - acc: 0.4167\n",
      "Epoch 45/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.8518 - acc: 0.437 - 0s 300us/step - loss: 1.9475 - acc: 0.4167\n",
      "Epoch 46/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.8483 - acc: 0.437 - 0s 317us/step - loss: 1.9524 - acc: 0.4167\n",
      "Epoch 47/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.7828 - acc: 0.437 - 0s 300us/step - loss: 1.8918 - acc: 0.4167\n",
      "Epoch 48/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.7454 - acc: 0.437 - 0s 300us/step - loss: 1.8856 - acc: 0.4167\n",
      "Epoch 49/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.7638 - acc: 0.437 - 0s 317us/step - loss: 1.8817 - acc: 0.4167\n",
      "Epoch 50/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.7988 - acc: 0.437 - 0s 300us/step - loss: 1.8828 - acc: 0.4167\n",
      "Epoch 51/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.6967 - acc: 0.437 - 0s 300us/step - loss: 1.8351 - acc: 0.4167\n",
      "Epoch 52/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.7236 - acc: 0.437 - 0s 350us/step - loss: 1.8105 - acc: 0.4167\n",
      "Epoch 53/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.6884 - acc: 0.437 - 0s 333us/step - loss: 1.8087 - acc: 0.4167\n",
      "Epoch 54/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.6334 - acc: 0.437 - 0s 300us/step - loss: 1.7508 - acc: 0.4167\n",
      "Epoch 55/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.6774 - acc: 0.437 - 0s 300us/step - loss: 1.7713 - acc: 0.4167\n",
      "Epoch 56/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.6496 - acc: 0.437 - 0s 333us/step - loss: 1.7387 - acc: 0.4167\n",
      "Epoch 57/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.5950 - acc: 0.437 - 0s 383us/step - loss: 1.7283 - acc: 0.4167\n",
      "Epoch 58/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.5929 - acc: 0.437 - 0s 300us/step - loss: 1.7518 - acc: 0.4167\n",
      "Epoch 59/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.5671 - acc: 0.437 - 0s 317us/step - loss: 1.6864 - acc: 0.4167\n",
      "Epoch 60/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.5680 - acc: 0.437 - 0s 267us/step - loss: 1.6912 - acc: 0.4167\n",
      "Epoch 61/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.5609 - acc: 0.437 - 0s 300us/step - loss: 1.6710 - acc: 0.4167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.5270 - acc: 0.437 - 0s 267us/step - loss: 1.6603 - acc: 0.4167\n",
      "Epoch 63/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.5551 - acc: 0.437 - 0s 267us/step - loss: 1.6704 - acc: 0.4167\n",
      "Epoch 64/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.4941 - acc: 0.437 - 0s 317us/step - loss: 1.5779 - acc: 0.4167\n",
      "Epoch 65/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.4701 - acc: 0.437 - 0s 283us/step - loss: 1.5997 - acc: 0.4167\n",
      "Epoch 66/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.4519 - acc: 0.437 - 0s 300us/step - loss: 1.5935 - acc: 0.4167\n",
      "Epoch 67/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.4190 - acc: 0.437 - 0s 333us/step - loss: 1.5671 - acc: 0.4167\n",
      "Epoch 68/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.4585 - acc: 0.437 - 0s 317us/step - loss: 1.5836 - acc: 0.4167\n",
      "Epoch 69/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.3851 - acc: 0.500 - 0s 283us/step - loss: 1.5024 - acc: 0.4667\n",
      "Epoch 70/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.4488 - acc: 0.531 - 0s 317us/step - loss: 1.5734 - acc: 0.4833\n",
      "Epoch 71/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.3441 - acc: 0.531 - 0s 350us/step - loss: 1.4615 - acc: 0.5167\n",
      "Epoch 72/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.3922 - acc: 0.531 - 0s 283us/step - loss: 1.5052 - acc: 0.5000\n",
      "Epoch 73/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.3411 - acc: 0.500 - 0s 317us/step - loss: 1.4754 - acc: 0.4667\n",
      "Epoch 74/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.3626 - acc: 0.562 - 0s 350us/step - loss: 1.4721 - acc: 0.4833\n",
      "Epoch 75/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.3230 - acc: 0.562 - 0s 333us/step - loss: 1.4402 - acc: 0.5167\n",
      "Epoch 76/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.3533 - acc: 0.500 - 0s 367us/step - loss: 1.4645 - acc: 0.4667\n",
      "Epoch 77/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.2379 - acc: 0.625 - 0s 333us/step - loss: 1.3595 - acc: 0.6000\n",
      "Epoch 78/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.2882 - acc: 0.531 - 0s 300us/step - loss: 1.4396 - acc: 0.5167\n",
      "Epoch 79/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.2581 - acc: 0.656 - 0s 367us/step - loss: 1.4189 - acc: 0.5667\n",
      "Epoch 80/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.3111 - acc: 0.468 - 0s 333us/step - loss: 1.3795 - acc: 0.4833\n",
      "Epoch 81/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.2966 - acc: 0.593 - 0s 367us/step - loss: 1.3893 - acc: 0.5333\n",
      "Epoch 82/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.2143 - acc: 0.562 - 0s 317us/step - loss: 1.3699 - acc: 0.5167\n",
      "Epoch 83/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.2570 - acc: 0.593 - 0s 333us/step - loss: 1.3536 - acc: 0.5667\n",
      "Epoch 84/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.2116 - acc: 0.593 - 0s 333us/step - loss: 1.3206 - acc: 0.5833\n",
      "Epoch 85/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.1859 - acc: 0.687 - 0s 317us/step - loss: 1.3005 - acc: 0.6167\n",
      "Epoch 86/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.1534 - acc: 0.625 - 0s 317us/step - loss: 1.3075 - acc: 0.5833\n",
      "Epoch 87/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.1626 - acc: 0.656 - 0s 267us/step - loss: 1.2586 - acc: 0.6167\n",
      "Epoch 88/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.1988 - acc: 0.562 - 0s 317us/step - loss: 1.3060 - acc: 0.5667\n",
      "Epoch 89/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.2365 - acc: 0.562 - 0s 333us/step - loss: 1.3250 - acc: 0.5833\n",
      "Epoch 90/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.1500 - acc: 0.531 - 0s 333us/step - loss: 1.2442 - acc: 0.5833\n",
      "Epoch 91/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.1489 - acc: 0.593 - 0s 333us/step - loss: 1.2315 - acc: 0.6333\n",
      "Epoch 92/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.1368 - acc: 0.593 - 0s 283us/step - loss: 1.2105 - acc: 0.6000\n",
      "Epoch 93/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.2343 - acc: 0.593 - 0s 300us/step - loss: 1.2740 - acc: 0.6000\n",
      "Epoch 94/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.0896 - acc: 0.687 - 0s 300us/step - loss: 1.2202 - acc: 0.6000\n",
      "Epoch 95/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.1067 - acc: 0.687 - 0s 317us/step - loss: 1.2456 - acc: 0.6667\n",
      "Epoch 96/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.1531 - acc: 0.656 - 0s 283us/step - loss: 1.2049 - acc: 0.7000\n",
      "Epoch 97/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.0440 - acc: 0.656 - 0s 300us/step - loss: 1.1699 - acc: 0.6833\n",
      "Epoch 98/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.0535 - acc: 0.687 - 0s 267us/step - loss: 1.1688 - acc: 0.6500\n",
      "Epoch 99/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.0252 - acc: 0.718 - 0s 317us/step - loss: 1.1383 - acc: 0.6667\n",
      "Epoch 100/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.0262 - acc: 0.687 - 0s 300us/step - loss: 1.1678 - acc: 0.6333\n",
      "Epoch 101/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.0189 - acc: 0.687 - 0s 333us/step - loss: 1.1590 - acc: 0.6500\n",
      "Epoch 102/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.0379 - acc: 0.656 - 0s 333us/step - loss: 1.1512 - acc: 0.6333\n",
      "Epoch 103/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.0640 - acc: 0.562 - 0s 317us/step - loss: 1.1847 - acc: 0.5833\n",
      "Epoch 104/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.0328 - acc: 0.625 - 0s 317us/step - loss: 1.1243 - acc: 0.6000\n",
      "Epoch 105/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.9937 - acc: 0.750 - 0s 417us/step - loss: 1.1511 - acc: 0.7000\n",
      "Epoch 106/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.0229 - acc: 0.625 - 0s 317us/step - loss: 1.0651 - acc: 0.6667\n",
      "Epoch 107/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.0186 - acc: 0.656 - 0s 300us/step - loss: 1.0996 - acc: 0.6500\n",
      "Epoch 108/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.9734 - acc: 0.687 - 0s 300us/step - loss: 1.0557 - acc: 0.6667\n",
      "Epoch 109/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 1.0417 - acc: 0.625 - 0s 300us/step - loss: 1.1321 - acc: 0.6333\n",
      "Epoch 110/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.9788 - acc: 0.781 - 0s 333us/step - loss: 1.1314 - acc: 0.7167\n",
      "Epoch 111/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.9380 - acc: 0.750 - 0s 317us/step - loss: 1.0892 - acc: 0.6833\n",
      "Epoch 112/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.9297 - acc: 0.812 - 0s 317us/step - loss: 1.0942 - acc: 0.7500\n",
      "Epoch 113/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.9993 - acc: 0.687 - 0s 333us/step - loss: 1.0893 - acc: 0.7167\n",
      "Epoch 114/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.9972 - acc: 0.687 - 0s 283us/step - loss: 1.0376 - acc: 0.7500\n",
      "Epoch 115/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.9383 - acc: 0.750 - 0s 300us/step - loss: 1.0938 - acc: 0.7000\n",
      "Epoch 116/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.9169 - acc: 0.687 - 0s 267us/step - loss: 0.9989 - acc: 0.7167\n",
      "Epoch 117/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.9882 - acc: 0.718 - 0s 300us/step - loss: 1.0608 - acc: 0.7000\n",
      "Epoch 118/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.8938 - acc: 0.718 - 0s 283us/step - loss: 0.9751 - acc: 0.6833\n",
      "Epoch 119/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.9377 - acc: 0.750 - 0s 267us/step - loss: 1.0469 - acc: 0.6833\n",
      "Epoch 120/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.8998 - acc: 0.687 - 0s 300us/step - loss: 0.9328 - acc: 0.7333\n",
      "Epoch 121/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.9921 - acc: 0.687 - 0s 317us/step - loss: 1.0343 - acc: 0.7333\n",
      "Epoch 122/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.9027 - acc: 0.718 - 0s 283us/step - loss: 1.0330 - acc: 0.6667\n",
      "Epoch 123/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.9150 - acc: 0.750 - 0s 300us/step - loss: 1.0177 - acc: 0.7000\n",
      "Epoch 124/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.8418 - acc: 0.812 - 0s 350us/step - loss: 0.9754 - acc: 0.7500\n",
      "Epoch 125/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.9044 - acc: 0.718 - 0s 300us/step - loss: 0.9479 - acc: 0.7333\n",
      "Epoch 126/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.8765 - acc: 0.750 - 0s 367us/step - loss: 0.9722 - acc: 0.7167\n",
      "Epoch 127/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.9331 - acc: 0.625 - 0s 333us/step - loss: 0.9447 - acc: 0.6833\n",
      "Epoch 128/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.8515 - acc: 0.812 - 0s 283us/step - loss: 0.9790 - acc: 0.7167\n",
      "Epoch 129/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.8094 - acc: 0.812 - 0s 300us/step - loss: 0.9153 - acc: 0.7667\n",
      "Epoch 130/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.8433 - acc: 0.781 - 0s 333us/step - loss: 0.9321 - acc: 0.7667\n",
      "Epoch 131/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.8134 - acc: 0.718 - 0s 300us/step - loss: 0.8948 - acc: 0.7167\n",
      "Epoch 132/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.8861 - acc: 0.718 - 0s 350us/step - loss: 0.9447 - acc: 0.7500\n",
      "Epoch 133/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.8293 - acc: 0.812 - 0s 300us/step - loss: 0.9241 - acc: 0.7667\n",
      "Epoch 134/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.9153 - acc: 0.781 - 0s 317us/step - loss: 0.9802 - acc: 0.7667\n",
      "Epoch 135/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.8067 - acc: 0.781 - 0s 317us/step - loss: 0.8911 - acc: 0.7833\n",
      "Epoch 136/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.8574 - acc: 0.718 - 0s 333us/step - loss: 0.9004 - acc: 0.7333\n",
      "Epoch 137/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.8696 - acc: 0.750 - 0s 300us/step - loss: 0.8868 - acc: 0.8000\n",
      "Epoch 138/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.7873 - acc: 0.781 - 0s 317us/step - loss: 0.8949 - acc: 0.7333\n",
      "Epoch 139/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.8600 - acc: 0.750 - 0s 383us/step - loss: 0.9102 - acc: 0.7833\n",
      "Epoch 140/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.8049 - acc: 0.812 - 0s 333us/step - loss: 0.8628 - acc: 0.8167\n",
      "Epoch 141/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.7873 - acc: 0.843 - 0s 300us/step - loss: 0.8503 - acc: 0.8000\n",
      "Epoch 142/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.7457 - acc: 0.750 - 0s 317us/step - loss: 0.8383 - acc: 0.7833\n",
      "Epoch 143/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.8009 - acc: 0.750 - 0s 317us/step - loss: 0.8595 - acc: 0.7833\n",
      "Epoch 144/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.7420 - acc: 0.843 - 0s 317us/step - loss: 0.8741 - acc: 0.8000\n",
      "Epoch 145/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.7962 - acc: 0.875 - 0s 333us/step - loss: 0.8358 - acc: 0.8167\n",
      "Epoch 146/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.8003 - acc: 0.843 - 0s 333us/step - loss: 0.8262 - acc: 0.8500\n",
      "Epoch 147/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.7462 - acc: 0.781 - 0s 300us/step - loss: 0.7865 - acc: 0.7833\n",
      "Epoch 148/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.7452 - acc: 0.718 - 0s 333us/step - loss: 0.7946 - acc: 0.7500\n",
      "Epoch 149/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.7896 - acc: 0.750 - 0s 333us/step - loss: 0.8200 - acc: 0.8000\n",
      "Epoch 150/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.7615 - acc: 0.875 - 0s 317us/step - loss: 0.8011 - acc: 0.8333\n",
      "Epoch 151/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.7387 - acc: 0.750 - 0s 283us/step - loss: 0.7803 - acc: 0.8000\n",
      "Epoch 152/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6845 - acc: 0.812 - 0s 267us/step - loss: 0.7306 - acc: 0.7833\n",
      "Epoch 153/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.7286 - acc: 0.781 - 0s 317us/step - loss: 0.7826 - acc: 0.7833\n",
      "Epoch 154/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6708 - acc: 0.906 - 0s 317us/step - loss: 0.7526 - acc: 0.9000\n",
      "Epoch 155/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.7231 - acc: 0.781 - 0s 317us/step - loss: 0.8262 - acc: 0.7500\n",
      "Epoch 156/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6453 - acc: 0.906 - 0s 333us/step - loss: 0.7327 - acc: 0.8833\n",
      "Epoch 157/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.7046 - acc: 0.875 - 0s 300us/step - loss: 0.7732 - acc: 0.8167\n",
      "Epoch 158/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6751 - acc: 0.843 - 0s 283us/step - loss: 0.7301 - acc: 0.8167\n",
      "Epoch 159/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6769 - acc: 0.812 - 0s 300us/step - loss: 0.7131 - acc: 0.8667\n",
      "Epoch 160/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6718 - acc: 0.843 - 0s 317us/step - loss: 0.7461 - acc: 0.8333\n",
      "Epoch 161/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.7740 - acc: 0.687 - 0s 300us/step - loss: 0.7697 - acc: 0.7833\n",
      "Epoch 162/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6665 - acc: 0.875 - 0s 300us/step - loss: 0.7082 - acc: 0.8833\n",
      "Epoch 163/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6889 - acc: 0.812 - 0s 300us/step - loss: 0.7187 - acc: 0.8333\n",
      "Epoch 164/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6591 - acc: 0.812 - 0s 300us/step - loss: 0.6971 - acc: 0.8000\n",
      "Epoch 165/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6046 - acc: 0.937 - 0s 317us/step - loss: 0.7043 - acc: 0.9000\n",
      "Epoch 166/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6411 - acc: 0.843 - 0s 300us/step - loss: 0.7506 - acc: 0.7667\n",
      "Epoch 167/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6331 - acc: 0.812 - 0s 267us/step - loss: 0.7088 - acc: 0.8167\n",
      "Epoch 168/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6465 - acc: 0.875 - 0s 317us/step - loss: 0.7116 - acc: 0.8833\n",
      "Epoch 169/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6374 - acc: 0.875 - 0s 333us/step - loss: 0.7030 - acc: 0.8500\n",
      "Epoch 170/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6142 - acc: 0.937 - 0s 300us/step - loss: 0.6737 - acc: 0.9000\n",
      "Epoch 171/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6808 - acc: 0.843 - 0s 250us/step - loss: 0.7164 - acc: 0.8667\n",
      "Epoch 172/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6669 - acc: 0.843 - 0s 317us/step - loss: 0.6669 - acc: 0.8667\n",
      "Epoch 173/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6951 - acc: 0.875 - 0s 283us/step - loss: 0.7640 - acc: 0.8333\n",
      "Epoch 174/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5473 - acc: 0.906 - 0s 317us/step - loss: 0.6277 - acc: 0.9167\n",
      "Epoch 175/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5928 - acc: 0.937 - 0s 250us/step - loss: 0.6397 - acc: 0.9000\n",
      "Epoch 176/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6075 - acc: 0.906 - 0s 300us/step - loss: 0.6714 - acc: 0.8667\n",
      "Epoch 177/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5554 - acc: 0.906 - 0s 283us/step - loss: 0.6101 - acc: 0.9000\n",
      "Epoch 178/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5748 - acc: 0.843 - 0s 317us/step - loss: 0.6263 - acc: 0.8667\n",
      "Epoch 179/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.6073 - acc: 0.843 - 0s 350us/step - loss: 0.6657 - acc: 0.8667\n",
      "Epoch 180/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5429 - acc: 0.875 - 0s 267us/step - loss: 0.6291 - acc: 0.8833\n",
      "Epoch 181/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5649 - acc: 0.875 - 0s 283us/step - loss: 0.5740 - acc: 0.9333\n",
      "Epoch 182/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - ETA: 0s - loss: 0.5663 - acc: 0.906 - 0s 300us/step - loss: 0.6300 - acc: 0.9000\n",
      "Epoch 183/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5101 - acc: 0.968 - 0s 333us/step - loss: 0.6417 - acc: 0.8833\n",
      "Epoch 184/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5282 - acc: 0.968 - 0s 283us/step - loss: 0.5730 - acc: 0.9500\n",
      "Epoch 185/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5773 - acc: 0.843 - 0s 367us/step - loss: 0.5786 - acc: 0.8667\n",
      "Epoch 186/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5958 - acc: 0.906 - 0s 350us/step - loss: 0.6494 - acc: 0.8833\n",
      "Epoch 187/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5778 - acc: 0.812 - 0s 367us/step - loss: 0.6066 - acc: 0.8500\n",
      "Epoch 188/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5452 - acc: 0.906 - 0s 333us/step - loss: 0.6144 - acc: 0.9000\n",
      "Epoch 189/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5362 - acc: 0.906 - 0s 283us/step - loss: 0.5742 - acc: 0.9000\n",
      "Epoch 190/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4889 - acc: 0.906 - 0s 317us/step - loss: 0.5454 - acc: 0.9333\n",
      "Epoch 191/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5440 - acc: 0.968 - 0s 333us/step - loss: 0.5824 - acc: 0.9500\n",
      "Epoch 192/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5110 - acc: 0.875 - 0s 300us/step - loss: 0.6331 - acc: 0.8500\n",
      "Epoch 193/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4761 - acc: 0.968 - 0s 300us/step - loss: 0.5732 - acc: 0.9167\n",
      "Epoch 194/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4519 - acc: 0.937 - 0s 350us/step - loss: 0.4908 - acc: 0.9500\n",
      "Epoch 195/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5201 - acc: 0.937 - 0s 367us/step - loss: 0.5623 - acc: 0.9333\n",
      "Epoch 196/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5455 - acc: 0.906 - 0s 283us/step - loss: 0.5550 - acc: 0.9333\n",
      "Epoch 197/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4887 - acc: 0.875 - 0s 317us/step - loss: 0.5280 - acc: 0.9000\n",
      "Epoch 198/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.4903 - acc: 0.937 - 0s 333us/step - loss: 0.5479 - acc: 0.9000\n",
      "Epoch 199/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.5499 - acc: 0.875 - 0s 300us/step - loss: 0.5950 - acc: 0.8833\n",
      "Epoch 200/200\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3959 - acc: 1.000 - 0s 317us/step - loss: 0.5022 - acc: 0.9667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_core.policies.keras_policy:Done fitting keras policy model\n",
      "INFO:rasa_core.agent:Model directory models/current/dialogue exists and contains old model files. All files will be overwritten.\n",
      "INFO:rasa_core.agent:Persisted model to 'D:\\Yogesh\\ToDos\\Projects\\Teaching\\Teaching_DataScience\\Jupyter\\bookingbot\\models\\current\\dialogue'\n"
     ]
    }
   ],
   "source": [
    "from rasa_core.policies import FallbackPolicy, KerasPolicy, MemoizationPolicy\n",
    "from rasa_core.agent import Agent\n",
    "\n",
    "# this will catch predictions the model isn't very certain about\n",
    "# there is a threshold for the NLU predictions as well as the action predictions\n",
    "fallback = FallbackPolicy(fallback_action_name=\"utter_unclear\",\n",
    "                          core_threshold=0.2,\n",
    "                          nlu_threshold=0.1)\n",
    "\n",
    "# agent = Agent('domain.yml', policies=[MemoizationPolicy(), KerasPolicy(), fallback])\n",
    "\n",
    "agent = Agent('config/domain.yml', policies = [MemoizationPolicy(max_history=2), KerasPolicy(validation_split=0.2,epochs=200)])\n",
    "# loading our neatly defined training dialogues\n",
    "training_data = agent.load_data('data/stories.md')\n",
    "\n",
    "agent.train(training_data)\n",
    "\n",
    "# FOLLOWING WAY HAS BEEN DEPRECATED, pass these parameters to KerasPolicy above\n",
    "# agent.train(\n",
    "#     training_data,\n",
    "#     validation_split=0.0,\n",
    "#     epochs=200\n",
    "# )\n",
    "\n",
    "agent.persist('models/current/dialogue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4911z6y-5rD"
   },
   "source": [
    "## Running: Talk to your Bot\n",
    "\n",
    "So we have the chatbot ready. It’s time to chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way is to run following command in shell (windows cmd)\n",
    "- activate the environment,\n",
    "- come to directory where actions.py is and then run\n",
    "- **python -m rasa_core.run -d models/current/dialogue -u models/current/nlu --endpoints endpoints.yml**\n",
    "\n",
    "Or else do programmatically like below\n",
    "\n",
    "Both approaches expect rasa core sdk server running in a separate window, else **python -m rasa_core_sdk.endpoint --actions actions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nE4coPam5hry",
    "outputId": "c8ec135b-882b-4e9e-a955-f3e184177817"
   },
   "outputs": [],
   "source": [
    "# #Starting the Bot\n",
    "\n",
    "# from rasa_core.agent import Agent\n",
    "# agent = Agent.load('models/current/dialogue', interpreter=model_directory)\n",
    "\n",
    "import IPython\n",
    "from IPython.display import clear_output\n",
    "from rasa_core.agent import Agent\n",
    "from rasa_core.interpreter import NaturalLanguageInterpreter\n",
    "from rasa_core.utils import EndpointConfig\n",
    "import time\n",
    "\n",
    "def load_assistant():\n",
    "    messages = [\"Hi! you can chat in this window. Type 'stop' to end the conversation.\"]\n",
    "    interpreter = NaturalLanguageInterpreter.create(model_directory)\n",
    "    endpoint = EndpointConfig('http://localhost:5055/webhook')\n",
    "    agent = Agent.load('models/current/dialogue', interpreter=interpreter, action_endpoint = endpoint)\n",
    "\n",
    "    print(\"start the conversation here or send 'stop'\")\n",
    "    print()\n",
    "    print(\"Hi! How Can I help you today?\")\n",
    "    while True:\n",
    "        a = input()\n",
    "        if a == 'stop':\n",
    "            break\n",
    "        responses = agent.handle_text(a)\n",
    "        for response in responses:\n",
    "            print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "DDVLzhAT5yrP",
    "outputId": "aee3fc83-df97-42b4-c7e0-c8929f76337c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_nlu.components:Added 'nlp_spacy' to component cache. Key 'nlp_spacy-en'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:\\Yogesh\\ToDos\\Projects\\Teaching\\Teaching_DataScience\\Jupyter\\bookingbot\\./models/nlu\\default\\chatter\\intent_classifier_tensorflow_embedding.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:\\Yogesh\\ToDos\\Projects\\Teaching\\Teaching_DataScience\\Jupyter\\bookingbot\\./models/nlu\\default\\chatter\\intent_classifier_tensorflow_embedding.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your bot is ready to talk! Type your messages here or send 'stop'\n",
      "Hi\n",
      "flight info\n",
      "We'll help you find the latest flight schedule. First, please provide your origin airport code?\n",
      "PNQ\n",
      "And the destination airport code?\n",
      "BLR\n",
      "What is the date for your travel(in dd-mm-yyyy)?\n",
      "29-05-2019\n",
      "I will be making inquiry for flight from PNQ to BLR on 29-05-2019. Is that correct?\n",
      "Yes\n",
      "Here is the list of carriers with their fare\n",
      "Spicejet : Rs.6,218\n",
      "IndiGo : Rs.3,876\n",
      "Do you want to make another inquiry?\n",
      "No\n",
      "Thanks for contacting us. Have a good day!\n"
     ]
    }
   ],
   "source": [
    "load_assistant()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "enJNkbvB54y1"
   },
   "source": [
    "## What Next?\n",
    "\n",
    "- Try to use different pipelines in Rasa Core, explore more Policies, fine-tune those models, \n",
    "- Check out what other features Make My Trip or any other similar site provides, etc.\n",
    "- Other APIs\n",
    "- Different languages (Hindi bot?)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "include_colab_link": true,
   "name": "Conversational_Chatbot.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:rasa] *",
   "language": "python",
   "name": "conda-env-rasa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
