{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3oxVq6vQ76r7"
   },
   "source": [
    "# IPL Chatbot\n",
    "\n",
    "Original: Learn how to Build and Deploy a Chatbot in Minutes using Rasa (IPL Case Study!) - Mohd Sanad Zaki Rizvi, Analytics Vidhya https://www.analyticsvidhya.com/blog/2019/04/learn-build-chatbot-rasa-nlp-ipl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kIFYA-Kp8aK4"
   },
   "source": [
    "**Objectives** To build a chatbot capable of fetching latest info about the ongoing IPL (Indian Premier League) matches from cricapi.com site.\n",
    "\n",
    "<img src=\"images/ipl.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rasa Stack\n",
    "\n",
    "- Lets you focus on improving the “Chatbot” part of your project \n",
    "- Default set up of Rasa works really well right out of the box for intent extraction and dialogue management\n",
    "- LOCAL models, no API calls for intent extraction and dialogue management, except if your business logic needs external calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture of chatbot\n",
    "\n",
    "<img src=\"images/rasa_full4.png\">\n",
    "\n",
    "\n",
    "- As soon as Rasa receives a message from the end user, it tries to predict or extract the “intent” and “entities” present in the message. This part is handled by Rasa NLU\n",
    "- Once the user’s intent is identified, the Rasa Stack performs an action called action_match_news to get the updates from the latest IPL match\n",
    "- Rasa then tries to predict what it should do next. This decision is taken considering multiple factors and is handled by Rasa Core\n",
    "- In this example, Rasa is showing the result of the most recent match to the user. It has also predicted the next action that our model should take – to check with the user whether the chatbot was able to solve his/her query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IVAF41hr8jU5"
   },
   "source": [
    "## Installations\n",
    "Official Documentation: https://rasa.com/docs/core/installation/\n",
    "* Python\n",
    "* Rasa Starter Pack\n",
    "* Spacy Language Model\n",
    "\n",
    "\n",
    "### Python\n",
    "* Install Anaconda 4.2.0 for Python 3.5 or Ananconda 5.2.0 for Python 3.6 \n",
    "* Windows Build tools: Make sure the Microsoft $VC++$ Compiler Visual Studio 2015 is installed, so python can compile any dependencies or https://visualstudio.microsoft.com/visual-cpp-build-tools/ Download the installer and select VC++ Build tools in the list.\n",
    "\n",
    "(My Note: on main page of Anaconda is https://www.anaconda.com/distribution/ you see Python 3.7, which is problematic, gives HTTP error while creating env. I had to delete 3.7 and get 3.6. Btw, this site does not mention which Anaconda installer has which Python version. WHY? thats the most crucial info. Anyway, I have given them here.)\n",
    "\n",
    "### Python Environment\n",
    "* By installing conda, you get base or the root environment, which is the default.\n",
    "* Practical tip: DO NOT install any packages in the root. ALWAYS create and env and install inside the new env.\n",
    "* Env is needed esepcially for fragile packages like Python (its treated as a package) and rasa.\n",
    "* So, **conda create -n rasa python=3.6** \n",
    "\n",
    "(My Note: Env management is again a sour point. It creates complete copy (deeeep) of python 3.6 and all other packages inside \"envs\" folder. Goes to 1.5 GB!! Can someone optimize it?)\n",
    "\n",
    "\n",
    "### IPL bot code (for reference)\n",
    "\n",
    "* Clone repo from https://github.com/mohdsanadzakirizvi/iplbot.git\n",
    "* \"Complete Version\" gives latest running application (Some modifications are needed, mentioned below)\n",
    "\n",
    "<!---\n",
    "* Let’s take a look at the folder structure and the files that were created \n",
    "<img src=\"images/nlu.png\">\n",
    "* Install git, can git clone above package.\n",
    "-->\n",
    "\n",
    "* **WE WILL BE CODING IT FROM SCRATCH**\n",
    "* Run following commands:\n",
    "\n",
    "* **mkdir code; cd code;mkdir data**\n",
    "* **activate rasa**\n",
    "* **pip install -r iplbot_requirements.txt** or **conda env create -f environment.yml**\n",
    "\n",
    "\n",
    "### Spacy Language Models\n",
    "* Open cmd in Administrator mode and activate the env\n",
    "* Download medium english by **python -m spacy download en_core_web_md** \n",
    "* Link with **python -m spacy link en_core_web_md en --force**\n",
    "\n",
    "\n",
    "(My Note: First command will show that linking is done, but it may not have happened actually. So, do next step anyway.)\n",
    "\n",
    "### Others\n",
    "* Install nb_conda_kernels to let Jupyter Notebook see the new env\n",
    "* Create account on cricapi.com (free, can login using Google account). Note down API Key and set it as CRICINFOAPI env variable\n",
    "\n",
    "<!---\n",
    "* Need Rasa Core SDK for custom actions **pip install rasa_core_sdk** and run it as **python -m rasa_core_sdk.endpoint --actions actions** where actions.py has all the custom actions\n",
    "* Install pygraphviz by **conda install -c alubbock pygraphviz**\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yHYeAA859JGq"
   },
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TSw6zFmk3iPu",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import logging, io, json, warnings\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "warnings.filterwarnings('ignore')\n",
    "# import rasa\n",
    "import rasa_nlu\n",
    "import rasa_core\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEw5vhSq9gWa"
   },
   "source": [
    "## Rasa NLU: Extracting User Intent from a Message\n",
    "\n",
    "The first thing we want to do is figure out the intent of the user. What does he or she want to accomplish? Let’s utilize Rasa and build an NLU model to identify user intent and its related entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oDEAOmaI9o4a"
   },
   "source": [
    "### Preparing the NLU Training Data\n",
    "\n",
    "Training data for extracting the user intent.\n",
    "As you can see, the format of training data for ‘intent’ is quite simple in Rasa. You just have to:\n",
    "\n",
    "- Start the line with “## intent:intent_name”\n",
    "- Supply all the examples in the following lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RPxeQ1_14CjK",
    "outputId": "bfb5974f-f8ea-46b8-b8cb-9dd4479ed9cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'nlu_md' (str) to file 'data/nlu_data.md'.\n"
     ]
    }
   ],
   "source": [
    "nlu_md = \"\"\"\n",
    "## intent:goodbye  \n",
    "- Bye \n",
    "- Goodbye\n",
    "- See you later\n",
    "- Bye bot\n",
    "- Goodbye friend\n",
    "- bye\n",
    "- bye for now\n",
    "- catch you later\n",
    "- gotta go\n",
    "- See you\n",
    "- goodnight\n",
    "- have a nice day\n",
    "- i'm off\n",
    "- see you later alligator\n",
    "- we'll speak soon\n",
    "- end\n",
    "- finish\n",
    "\n",
    "## intent:greet\n",
    "- Hi\n",
    "- Hey\n",
    "- Hi bot\n",
    "- Hey bot\n",
    "- Hello\n",
    "- Good morning\n",
    "- hi again\n",
    "- hi folks\n",
    "- hi Mister\n",
    "- hi pal!\n",
    "- hi there\n",
    "- greetings\n",
    "- hello everybody\n",
    "- hello is anybody there\n",
    "- hello robot\n",
    "- who are you?\n",
    "- what are you?\n",
    "- what's up\n",
    "- how do you do?\n",
    "\n",
    "## intent:thanks\n",
    "- Thanks\n",
    "- Thank you\n",
    "- Thank you so much\n",
    "- Thanks bot\n",
    "- Thanks for that\n",
    "- cheers\n",
    "- cheers bro\n",
    "- ok thanks!\n",
    "- perfect thank you\n",
    "- thanks a bunch for everything\n",
    "- thanks for the help\n",
    "- thanks a lot\n",
    "- amazing, thanks\n",
    "- cool, thanks\n",
    "- cool thank you\n",
    "\n",
    "## intent:affirm\n",
    "- y\n",
    "- Y\n",
    "- yes\n",
    "- yes sure\n",
    "- absolutely\n",
    "- for sure\n",
    "- yes yes yes\n",
    "- definitely\n",
    "- yes, it did.\n",
    "\n",
    "## intent:current_matches\n",
    "- what are the current matches\n",
    "- can you list the matches in ipl 2019\n",
    "- which cricket match is happening right now\n",
    "- which ipl match is next\n",
    "- which teams are playing next in ipl\n",
    "- which team will play next in ipl\n",
    "- tell me some ipl news\n",
    "- i want ipl updates\n",
    "- can you give me ipl latest updates\n",
    "- what are the latest match updates\n",
    "- who won the last ipl match\n",
    "- which teams are competing in the next match\n",
    "- how is ipl going\n",
    "- what was the result of the last match\n",
    "- when is the next match\n",
    "\n",
    "## intent:deny\n",
    "- no\n",
    "- never\n",
    "- I don't think so\n",
    "- don't like that\n",
    "- no way\n",
    "- not really\n",
    "- n\n",
    "- N\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > data/nlu_data.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can include as many examples as you want for each intent. In fact, make sure to include slangs and short forms that you use while texting. The idea is to make the chatbot understand the way we type text. Feel free to refer to the complete version where I have given plenty of examples for each intent type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ceazcacn9veB"
   },
   "source": [
    "### Defining the NLU Model Configuration\n",
    "\n",
    "This file lets us create a text processing pipeline in Rasa. Luckily for us, Rasa comes with two default settings based on the amount of training data we have:\n",
    "- “spacy_sklearn” pipeline if you have less than 1000 training examples\n",
    "- “tensorflow_embedding” if you have a large amount of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dF60NWhR4ID6",
    "outputId": "92946645-94fc-4450-aa41-eca8895ff83c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'config' (str) to file 'config/nlu_config.yml'.\n"
     ]
    }
   ],
   "source": [
    "config = \"\"\"\n",
    "language: \"en\"\n",
    "pipeline: spacy_sklearn\n",
    "\"\"\" \n",
    "\n",
    "%store config > config/nlu_config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ieoWk91X9y8X"
   },
   "source": [
    "### Training the NLU Classifier Model\n",
    "\n",
    "On command line you can run following command:\n",
    "\n",
    "**python -m rasa_nlu.train -c nlu_config.yml --data data/nlu_data.md -o models --fixed_model_name nlu --project current --verbose**\n",
    "\n",
    "Or programmatically you can write code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "dp3AIHmS4L6x",
    "outputId": "8011c4f7-c789-4138-84d7-4710207615d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\yogesh.kulkarni\\AppData\\Local\\Continuum\\anaconda3\\envs\\rasa\\lib\\site-packages\\tensor2tensor\\utils\\adafactor.py:27: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\yogesh.kulkarni\\AppData\\Local\\Continuum\\anaconda3\\envs\\rasa\\lib\\site-packages\\tensor2tensor\\utils\\multistep_optimizer.py:32: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\yogesh.kulkarni\\AppData\\Local\\Continuum\\anaconda3\\envs\\rasa\\lib\\site-packages\\mesh_tensorflow\\ops.py:4237: The name tf.train.CheckpointSaverListener is deprecated. Please use tf.estimator.CheckpointSaverListener instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\yogesh.kulkarni\\AppData\\Local\\Continuum\\anaconda3\\envs\\rasa\\lib\\site-packages\\mesh_tensorflow\\ops.py:4260: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\yogesh.kulkarni\\AppData\\Local\\Continuum\\anaconda3\\envs\\rasa\\lib\\site-packages\\tensor2tensor\\models\\research\\neural_stack.py:51: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.\n",
      "\n",
      "INFO:absl:Entry Point [tensor2tensor.envs.tic_tac_toe_env:TicTacToeEnv] registered with id [T2TEnv-TicTacToeEnv-v0]\n",
      "WARNING:tensorflow:From C:\\Users\\yogesh.kulkarni\\AppData\\Local\\Continuum\\anaconda3\\envs\\rasa\\lib\\site-packages\\tensor2tensor\\utils\\trainer_lib.py:111: The name tf.OptimizerOptions is deprecated. Please use tf.compat.v1.OptimizerOptions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\yogesh.kulkarni\\AppData\\Local\\Continuum\\anaconda3\\envs\\rasa\\lib\\site-packages\\tensorflow_gan\\python\\contrib_utils.py:305: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\yogesh.kulkarni\\AppData\\Local\\Continuum\\anaconda3\\envs\\rasa\\lib\\site-packages\\tensorflow_gan\\python\\contrib_utils.py:310: The name tf.estimator.tpu.TPUEstimatorSpec is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimatorSpec instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\yogesh.kulkarni\\AppData\\Local\\Continuum\\anaconda3\\envs\\rasa\\lib\\site-packages\\rasa\\utils\\train_utils.py:28: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:rasa_nlu.config:You have specified the pipeline template 'spacy_sklearn' which has been renamed to 'pretrained_embeddings_spacy'. Please update your code as it will no longer work with future versions of Rasa NLU.\n",
      "INFO:rasa.nlu.utils.spacy_utils:Trying to load spacy model with name 'en'\n",
      "INFO:rasa.nlu.components:Added 'SpacyNLP' to component cache. Key 'SpacyNLP-en'.\n",
      "INFO:rasa_nlu.model:Starting to train component SpacyNLP\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component SpacyTokenizer\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component SpacyFeaturizer\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component RegexFeaturizer\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component CRFEntityExtractor\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component EntitySynonymMapper\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component SklearnIntentClassifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.0s finished\n",
      "C:\\Users\\yogesh.kulkarni\\AppData\\Local\\Continuum\\anaconda3\\envs\\rasa\\lib\\site-packages\\sklearn\\model_selection\\_search.py:842: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Successfully saved model into 'C:\\YogeshKulkarni\\Training\\TeachingDataScience\\Jupyter\\models\\nlu\\current'\n"
     ]
    }
   ],
   "source": [
    "from rasa_nlu.training_data import load_data\n",
    "# from rasa_nlu.converters import load_data\n",
    "from rasa_nlu.config import RasaNLUModelConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "from rasa_nlu import config\n",
    "\n",
    "# loading the nlu training samples\n",
    "training_data = load_data(\"data/nlu_data.md\")\n",
    "\n",
    "# trainer to educate our pipeline\n",
    "trainer = Trainer(config.load(\"config/nlu_config.yml\"))\n",
    "\n",
    "# train the model!\n",
    "interpreter = trainer.train(training_data)\n",
    "\n",
    "# store it for future use\n",
    "model_directory = trainer.persist(\"./models/nlu\", fixed_model_name=\"current\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jrfp4xOS95ZZ"
   },
   "source": [
    "### Evaluating the NLU model on a random text (first way)\n",
    "\n",
    "Let’s test how good our model is performing by giving it a sample text that it hasn’t been trained on for extracting intent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "4UjzlqMV4N1k",
    "outputId": "37ea93e5-6a71-4e8e-d2b6-a45144d184ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"current_matches\",\n",
      "    \"confidence\": 0.5027458339717834\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"current_matches\",\n",
      "      \"confidence\": 0.5027458339717834\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.26801601848949613\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.09570077132137719\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.05384840842567026\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.04753532943282141\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.03215363835885181\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"what is happening in the cricket world these days?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# A helper function for prettier output\n",
    "\n",
    "def pprint(o):   \n",
    "    print(json.dumps(o, indent=2))\n",
    "    \n",
    "pprint(interpreter.parse(\"what is happening in the cricket world these days?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only does our NLU model perform well on intent extraction, but it also ranks the other intents based on their confidence scores. This is a nifty little feature that can be really useful when the classifier is confused between multiple intents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the NLU model on a random text (2nd way)\n",
    "Let’s test how good our model is performing by giving it a sample text that it hasn’t been trained on for extracting intent. You can open an iPython/Python shell and follow the following steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa.nlu.components:Added 'SpacyNLP' to component cache. Key 'SpacyNLP-en'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'intent': {'name': 'current_matches', 'confidence': 0.5027458339717834},\n",
       " 'entities': [],\n",
       " 'intent_ranking': [{'name': 'current_matches',\n",
       "   'confidence': 0.5027458339717834},\n",
       "  {'name': 'greet', 'confidence': 0.26801601848949613},\n",
       "  {'name': 'goodbye', 'confidence': 0.09570077132137719},\n",
       "  {'name': 'affirm', 'confidence': 0.05384840842567026},\n",
       "  {'name': 'deny', 'confidence': 0.04753532943282141},\n",
       "  {'name': 'thanks', 'confidence': 0.03215363835885181}],\n",
       " 'text': 'what is happening in the cricket world these days?'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rasa_nlu.model import Interpreter\n",
    "nlu_model = Interpreter.load('./models/nlu/current')\n",
    "nlu_model.parse('what is happening in the cricket world these days?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OPlSd-As-Fz4"
   },
   "source": [
    "### Evaluating the NLU model on a test data\n",
    "(Here we are using the data at hand i.e nlu.md but it isr recommended to use unseen data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1483
    },
    "colab_type": "code",
    "id": "FmRCylbT4jyw",
    "outputId": "fd1bfd57-ebb3-4541-d3b3-b4cbba781164"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa.nlu.components:Added 'SpacyNLP' to component cache. Key 'SpacyNLP-en'.\n",
      "INFO:rasa_nlu.test:Running model for predictions:\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 83/83 [00:00<00:00, 243.27it/s]\n",
      "INFO:rasa_nlu.test:Intent evaluation results:\n",
      "INFO:rasa_nlu.test:Intent Evaluation: Only considering those 83 examples that have a defined intent out of 83 examples\n",
      "INFO:rasa_nlu.test:F1-Score:  1.0\n",
      "INFO:rasa_nlu.test:Precision: 1.0\n",
      "INFO:rasa_nlu.test:Accuracy:  1.0\n",
      "INFO:rasa_nlu.test:Classification report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           deny       1.00      1.00      1.00         8\n",
      "         thanks       1.00      1.00      1.00        15\n",
      "         affirm       1.00      1.00      1.00         9\n",
      "          greet       1.00      1.00      1.00        19\n",
      "current_matches       1.00      1.00      1.00        15\n",
      "        goodbye       1.00      1.00      1.00        17\n",
      "\n",
      "      micro avg       1.00      1.00      1.00        83\n",
      "      macro avg       1.00      1.00      1.00        83\n",
      "   weighted avg       1.00      1.00      1.00        83\n",
      "\n",
      "INFO:rasa_nlu.test:Entity evaluation results:\n",
      "INFO:rasa_nlu.test:Evaluation for entity extractor: CRFEntityExtractor \n",
      "WARNING:rasa_nlu.test:No labels to evaluate. Skip evaluation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'intent_evaluation': {'predictions': [{'text': 'Bye',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.9625516082195371},\n",
       "   {'text': 'Goodbye',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.8715724602447923},\n",
       "   {'text': 'See you later',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.7904279765230119},\n",
       "   {'text': 'Bye bot',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.8022173445689474},\n",
       "   {'text': 'Goodbye friend',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.8181345725239519},\n",
       "   {'text': 'bye',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.9625516082195371},\n",
       "   {'text': 'bye for now',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.7604057542806846},\n",
       "   {'text': 'catch you later',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.7599193234512406},\n",
       "   {'text': 'gotta go',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.7887576327399813},\n",
       "   {'text': 'See you',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.7450600929792883},\n",
       "   {'text': 'goodnight',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.8715724602447923},\n",
       "   {'text': 'have a nice day',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.7289276436198051},\n",
       "   {'text': \"i'm off\",\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.7652700179304718},\n",
       "   {'text': 'see you later alligator',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.758594670178781},\n",
       "   {'text': \"we'll speak soon\",\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.7538988925616306},\n",
       "   {'text': 'end',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.8103239799462788},\n",
       "   {'text': 'finish',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.837760826955922},\n",
       "   {'text': 'Hi',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.9837496625025949},\n",
       "   {'text': 'Hey',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.8863573561277668},\n",
       "   {'text': 'Hi bot',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.8790788113514004},\n",
       "   {'text': 'Hey bot',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.7981885237665012},\n",
       "   {'text': 'Hello',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.9298689283967604},\n",
       "   {'text': 'Good morning',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.8075942876016504},\n",
       "   {'text': 'hi again',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.8185792269457441},\n",
       "   {'text': 'hi folks',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.8835991203721997},\n",
       "   {'text': 'hi Mister',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.959951217558227},\n",
       "   {'text': 'hi pal!',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.8699217524926681},\n",
       "   {'text': 'hi there',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.879049843399541},\n",
       "   {'text': 'greetings',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.8528186116509167},\n",
       "   {'text': 'hello everybody',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.8890352887131202},\n",
       "   {'text': 'hello is anybody there',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.7684266756305553},\n",
       "   {'text': 'hello robot',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.8502861871731802},\n",
       "   {'text': 'who are you?',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.7803019678569529},\n",
       "   {'text': 'what are you?',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.8065267530028992},\n",
       "   {'text': \"what's up\",\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.7695904489481548},\n",
       "   {'text': 'how do you do?',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.7932136615021248},\n",
       "   {'text': 'Thanks',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.9979266258780325},\n",
       "   {'text': 'Thank you',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.8719393468885299},\n",
       "   {'text': 'Thank you so much',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.6933677752352703},\n",
       "   {'text': 'Thanks bot',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.78473158897128},\n",
       "   {'text': 'Thanks for that',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.7377295152446072},\n",
       "   {'text': 'cheers',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.9309781474112232},\n",
       "   {'text': 'cheers bro',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.8197182065023221},\n",
       "   {'text': 'ok thanks!',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.7774696672222328},\n",
       "   {'text': 'perfect thank you',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.7252155163391559},\n",
       "   {'text': 'thanks a bunch for everything',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.6860559585211753},\n",
       "   {'text': 'thanks for the help',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.6947638469859345},\n",
       "   {'text': 'thanks a lot',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.7910380656092652},\n",
       "   {'text': 'amazing, thanks',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.8613332174000794},\n",
       "   {'text': 'cool, thanks',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.7810881595334874},\n",
       "   {'text': 'cool thank you',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.7920878140357526},\n",
       "   {'text': 'y',\n",
       "    'intent': 'affirm',\n",
       "    'predicted': 'affirm',\n",
       "    'confidence': 0.7774367186833971},\n",
       "   {'text': 'Y',\n",
       "    'intent': 'affirm',\n",
       "    'predicted': 'affirm',\n",
       "    'confidence': 0.7774367186833971},\n",
       "   {'text': 'yes',\n",
       "    'intent': 'affirm',\n",
       "    'predicted': 'affirm',\n",
       "    'confidence': 0.819122545514083},\n",
       "   {'text': 'yes sure',\n",
       "    'intent': 'affirm',\n",
       "    'predicted': 'affirm',\n",
       "    'confidence': 0.7579213603177327},\n",
       "   {'text': 'absolutely',\n",
       "    'intent': 'affirm',\n",
       "    'predicted': 'affirm',\n",
       "    'confidence': 0.7708578032509137},\n",
       "   {'text': 'for sure',\n",
       "    'intent': 'affirm',\n",
       "    'predicted': 'affirm',\n",
       "    'confidence': 0.7089854424261738},\n",
       "   {'text': 'yes yes yes',\n",
       "    'intent': 'affirm',\n",
       "    'predicted': 'affirm',\n",
       "    'confidence': 0.8191225452067933},\n",
       "   {'text': 'definitely',\n",
       "    'intent': 'affirm',\n",
       "    'predicted': 'affirm',\n",
       "    'confidence': 0.7158257385448873},\n",
       "   {'text': 'yes, it did.',\n",
       "    'intent': 'affirm',\n",
       "    'predicted': 'affirm',\n",
       "    'confidence': 0.7380656223715087},\n",
       "   {'text': 'what are the current matches',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.7121750503599314},\n",
       "   {'text': 'can you list the matches in ipl 2019',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.8166024607798348},\n",
       "   {'text': 'which cricket match is happening right now',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.7331532591610271},\n",
       "   {'text': 'which ipl match is next',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.9372677789018696},\n",
       "   {'text': 'which teams are playing next in ipl',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.8001413030442027},\n",
       "   {'text': 'which team will play next in ipl',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.8466435153943096},\n",
       "   {'text': 'tell me some ipl news',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.713075771822278},\n",
       "   {'text': 'i want ipl updates',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.755903642295565},\n",
       "   {'text': 'can you give me ipl latest updates',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.696432060185879},\n",
       "   {'text': 'what are the latest match updates',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.7851242906589456},\n",
       "   {'text': 'who won the last ipl match',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.9178764337398214},\n",
       "   {'text': 'which teams are competing in the next match',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.709012900447511},\n",
       "   {'text': 'how is ipl going',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.7302330037623069},\n",
       "   {'text': 'what was the result of the last match',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.6774804637212585},\n",
       "   {'text': 'when is the next match',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.7011439871335015},\n",
       "   {'text': 'no',\n",
       "    'intent': 'deny',\n",
       "    'predicted': 'deny',\n",
       "    'confidence': 0.8955444558088306},\n",
       "   {'text': 'never',\n",
       "    'intent': 'deny',\n",
       "    'predicted': 'deny',\n",
       "    'confidence': 0.7778702874450314},\n",
       "   {'text': \"I don't think so\",\n",
       "    'intent': 'deny',\n",
       "    'predicted': 'deny',\n",
       "    'confidence': 0.6591978409076773},\n",
       "   {'text': \"don't like that\",\n",
       "    'intent': 'deny',\n",
       "    'predicted': 'deny',\n",
       "    'confidence': 0.6595810250879313},\n",
       "   {'text': 'no way',\n",
       "    'intent': 'deny',\n",
       "    'predicted': 'deny',\n",
       "    'confidence': 0.656224645398554},\n",
       "   {'text': 'not really',\n",
       "    'intent': 'deny',\n",
       "    'predicted': 'deny',\n",
       "    'confidence': 0.7131097367025863},\n",
       "   {'text': 'n',\n",
       "    'intent': 'deny',\n",
       "    'predicted': 'deny',\n",
       "    'confidence': 0.654900994068484},\n",
       "   {'text': 'N',\n",
       "    'intent': 'deny',\n",
       "    'predicted': 'deny',\n",
       "    'confidence': 0.654900994068484}],\n",
       "  'report': '                 precision    recall  f1-score   support\\n\\n           deny       1.00      1.00      1.00         8\\n         thanks       1.00      1.00      1.00        15\\n         affirm       1.00      1.00      1.00         9\\n          greet       1.00      1.00      1.00        19\\ncurrent_matches       1.00      1.00      1.00        15\\n        goodbye       1.00      1.00      1.00        17\\n\\n      micro avg       1.00      1.00      1.00        83\\n      macro avg       1.00      1.00      1.00        83\\n   weighted avg       1.00      1.00      1.00        83\\n',\n",
       "  'precision': 1.0,\n",
       "  'f1_score': 1.0,\n",
       "  'accuracy': 1.0},\n",
       " 'entity_evaluation': {'CRFEntityExtractor': {'report': {},\n",
       "   'precision': 0.0,\n",
       "   'f1_score': 0.0,\n",
       "   'accuracy': 0.0}},\n",
       " 'response_selection_evaluation': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rasa_nlu.test import run_evaluation\n",
    "\n",
    "run_evaluation(\"data/nlu_data.md\", model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Av3R2GZZ-WJO"
   },
   "source": [
    "## Rasa Core: Making Interactive Conversations\n",
    "\n",
    "One of the most important aspects of a chatbot application is its ability to be interactive. \n",
    "\n",
    "### Designing the conversational flow\n",
    "\n",
    "Think of the simplest conversation our chatbot can have with a user. What would be the flow of such a conversation?\n",
    "\n",
    "---\n",
    "Me: Hi\n",
    "\n",
    "Iplbot: Hey! How may I help you?\n",
    "\n",
    "Me: What was the result of the last match?\n",
    "\n",
    "Iplbot: Here are some IPL quick info:\n",
    "1.The match between Rajasthan Royals and Delhi Capitals was recently held and Delhi Capitals won.\n",
    "2.The next match is Warriors vs Titans on 22 April 2019\n",
    "\n",
    "Iplbot: Did that help you?\n",
    "\n",
    "Me: yes, thank you!\n",
    "\n",
    "Iplbot: Glad that I could help!\n",
    "\n",
    "---\n",
    "Let’s see how we can teach a simple conversation like that to Rasa:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## news path 1\n",
    "* greet\n",
    "  - utter_greet\n",
    "* current_matches\n",
    "  - action_match_news\n",
    "  - utter_did_that_help\n",
    "* affirm or thanks\n",
    "  - utter_gratitude\n",
    "* goodbye\n",
    "  - utter_goodbye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general format is:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## news path 1           <--- story name for debugging purposes\n",
    "* greet                  <--- intent detected from the user\n",
    "  - utter_greet          <--- what action the bot should take\n",
    "* current_matches        <--- the following intent in the conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is called a user story path. I have provided a few stories in the data/stories.md file for your reference. This is the training data for Rasa Core."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BKZ63AuS-ZPV"
   },
   "source": [
    "### Writing  Stories\n",
    "\n",
    "The way it works is:\n",
    "\n",
    "- Give some examples of sample story paths that the user is expected to follow\n",
    "- Rasa Core combines them randomly to create more complex user paths\n",
    "- It then builds a probabilistic model out of that. This model is used to predict the next action Rasa should take\n",
    "\n",
    "<img src=\"images/conversation_flow.png\">\n",
    "\n",
    "The above illustration might look complicated, but it’s simply listing out various possible user stories that I have taught Rasa. Here are a few things to note from the above graph:\n",
    "\n",
    "- Except for the START and END boxes, all the colored boxes indicate user intent\n",
    "- All the white boxes are actions that the chatbot performs\n",
    "- Arrows indicate the flow of the conversation\n",
    "- action_match_news is where we hit the CricAPI to get IPL information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W3q1XJ5O4orY",
    "outputId": "a82511c7-b7e5-462c-c5c2-35df3cabd39a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'stories_md' (str) to file 'data/stories.md'.\n"
     ]
    }
   ],
   "source": [
    "stories_md = \"\"\"\n",
    "## news path 1\n",
    "* greet\n",
    "  - utter_greet\n",
    "* current_matches\n",
    "  - action_match_news\n",
    "  - utter_did_that_help\n",
    "* affirm or thanks\n",
    "  - utter_gratitude\n",
    "* goodbye\n",
    "  - utter_goodbye\n",
    "\n",
    "## news path 2\n",
    "* current_matches\n",
    "  - action_match_news\n",
    "  - utter_did_that_help\n",
    "* affirm or thanks\n",
    "  - utter_gratitude\n",
    "* goodbye\n",
    "  - utter_goodbye\n",
    "\n",
    "## news path 3\n",
    "* greet\n",
    "  - utter_greet\n",
    "* current_matches\n",
    "  - action_match_news\n",
    "  - utter_did_that_help\n",
    "* deny\n",
    "  - utter_ask_again\n",
    "* current_matches\n",
    "  - action_match_news\n",
    "  - utter_did_that_help\n",
    "* affirm or thanks\n",
    "  - utter_gratitude\n",
    "* goodbye\n",
    "  - utter_goodbye\n",
    "\n",
    "## greet path\n",
    "* greet\n",
    "  - utter_greet\n",
    "\n",
    "## goodbye path\n",
    "* goodbye\n",
    "  - utter_goodbye\n",
    "\"\"\"\n",
    "\n",
    "%store stories_md > data/stories.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, generate a similar graph for your stories using the following command:\n",
    "\n",
    "**python -m rasa_core.visualize -d domain.yml -s data/stories.md -o graph.html**\n",
    "\n",
    "This is very helpful when debugging the conversational flow of the chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LnD9v_CX-ePm"
   },
   "source": [
    "### Defining the Domain\n",
    "\n",
    "The domain is the world of your chatbot. It contains everything the chatbot should know, including:\n",
    "\n",
    "- All the actions it is capable of doing\n",
    "- The intents it should understand\n",
    "- The template of all the utterances it should tell the user, and much more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3SzQq1oy5U9T",
    "outputId": "4fde8c0d-9672-457c-cacc-0e86d3ca5c80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'domain_yml' (str) to file 'config/domain.yml'.\n"
     ]
    }
   ],
   "source": [
    "domain_yml = \"\"\"\n",
    "actions:\n",
    "- utter_greet\n",
    "- utter_did_that_help\n",
    "- utter_goodbye\n",
    "- action_match_news\n",
    "- utter_default\n",
    "- utter_gratitude\n",
    "- utter_ask_again\n",
    "\n",
    "intents:\n",
    "- goodbye\n",
    "- greet\n",
    "- thanks\n",
    "- current_matches\n",
    "- affirm\n",
    "- deny\n",
    "\n",
    "templates:\n",
    "  utter_greet:\n",
    "  - text: \"Hey! What can I do for you?\"\n",
    "  utter_did_that_help:\n",
    "  - text: \"Did that help you?\"\n",
    "  - text: \"I hope that solved your query\"\n",
    "  utter_goodbye:\n",
    "  - text: \"Bye\"\n",
    "  utter_default:\n",
    "  - text: \"I am sorry, I didn't get that. Could you please repeat your query?\"\n",
    "  - text: \"I am not sure what you are aiming for.\"\n",
    "  utter_gratitude:\n",
    "  - text: \"Glad that I could be of help to you!\\nBye\"\n",
    "  utter_ask_again:\n",
    "  - text: \"Okay! Let's start again, please tell me what do you need?\"\n",
    "  - text: \"No issues! Let's try this again.\\n Please repeat your query?\"\n",
    "\"\"\"\n",
    "\n",
    "%store domain_yml > config/domain.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Policies\n",
    "\n",
    "Rasa Core generates the training data for the conversational part using the stories we provide. It also lets you define a set of policies to use when deciding the next action of the chatbot. These policies are defined in the policies.yml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'policies_yml' (str) to file 'config/policies.yml'.\n"
     ]
    }
   ],
   "source": [
    "policies_yml = \"\"\"\n",
    "policies:\n",
    "  - name: KerasPolicy\n",
    "    epochs: 100\n",
    "    max_history: 5\n",
    "  - name: FallbackPolicy\n",
    "    fallback_action_name: 'action_default_fallback'\n",
    "  - name: MemoizationPolicy\n",
    "    max_history: 5\n",
    "\"\"\"\n",
    "\n",
    "%store policies_yml > config/policies.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- KerasPolicy uses a neural network implemented in Keras to select the next action. The default architecture is based on an LSTM (Long Short Term Memory) model\n",
    "- MemoizationPolicy memorizes the conversations in your training data. It predicts the next action with confidence 1.0 if this exact conversation exists in the training data, otherwise, it predicts ‘None’ with confidence 0.0\n",
    "- FallbackPolicy invokes a fallback action if the intent recognition has confidence below nlu_threshold or if none of the dialogue policies predict action with confidence higher than core_threshold\n",
    "- One important hyperparameter for Rasa Core policies is the max_history. This controls how much dialogue history the model looks at to decide which action to take next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ROL3AYs5-iCg"
   },
   "source": [
    "###  Custom Actions\n",
    "\n",
    "Using CricAPI for fetching IPL related news. It is free for 100 requests per day, which (I hope) is more than enough to satiate that cricket crazy passion you have.\n",
    "\n",
    "You need to first signup on the website to get access to their API:\n",
    "https://www.cricapi.com/\n",
    "\n",
    "You should be able to see your API Key once you are logged in:\n",
    "\n",
    "<img src=\"images/lala-1140x399.png\">\n",
    "\n",
    "Modifications to original code:\n",
    "\n",
    "- Instead of showing API key here it has been stored in ENV variable and fetched here\n",
    "- Key \"toss_winner_team\" was subsituted into depreceated key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7SbmLMJa5X0E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'actions_py' (str) to file 'actions.py'.\n"
     ]
    }
   ],
   "source": [
    "actions_py=\"\"\"\n",
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "from datetime import datetime\n",
    "\n",
    "import logging\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from rasa_core_sdk import Action\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "API_URL = \"https://cricapi.com/api/\"\n",
    "API_KEY = os.environ.get('CRICINFOAPI')\n",
    "\n",
    "class ApiAction(Action):\n",
    "    def name(self):\n",
    "        return \"action_match_news\"\n",
    "\n",
    "    def run(self, dispatcher, tracker, domain):\n",
    "        print(API_URL + \"matches\" + \"?apikey=\" + API_KEY)\n",
    "        res = requests.get(API_URL + \"matches\" + \"?apikey=\" + API_KEY) #, verify=False\n",
    "        if res.status_code == 200:\n",
    "            data = res.json()[\"matches\"]\n",
    "            recent_match = data[0]\n",
    "            upcoming_match = data[1]\n",
    "            upcoming_match[\"date\"] = datetime.strptime(upcoming_match[\"date\"], \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "            next_date = upcoming_match[\"date\"].strftime(\"%d %B %Y\")\n",
    "\n",
    "            out_message = \"Here some IPL quick info: 1.The match between {} and {} was recently held and {} won the toss.\".format(recent_match[\"team-1\"], recent_match[\"team-2\"], recent_match[\"toss_winner_team\"])\n",
    "\n",
    "            dispatcher.utter_message(out_message)\n",
    "\n",
    "            out_message = \"2.The next match is {} vs {} on {}\".format(upcoming_match[\"team-1\"], upcoming_match[\"team-2\"], next_date)\n",
    "\n",
    "            dispatcher.utter_message(out_message)\n",
    "\n",
    "            return []\n",
    "\"\"\"\n",
    "%store actions_py > actions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need endpoints yml to execute the actions server.\n",
    "\n",
    "Note: If you have external API call, like REST, need to have \"webhook\" word at the end, else nothing.\n",
    "\n",
    "My own query on this topic: https://forum.rasa.com/t/rasa-core-sdk-not-working/9228"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'endpoints_yml' (str) to file 'endpoints.yml'.\n"
     ]
    }
   ],
   "source": [
    "endpoints_yml = \"\"\"\n",
    "#action_endpoint:\n",
    "#  url: \"http://localhost:5055/webhook\"\n",
    "  \n",
    "action_endpoint:\n",
    "  url: http://localhost:5055/webhook\n",
    "\n",
    "#nlg:\n",
    "#  url: http://localhost:5056/nlg\n",
    "\n",
    "core_endpoint:\n",
    "  url: http://localhost:5005\n",
    "\"\"\"\n",
    "%store endpoints_yml > endpoints.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a separate shell (cmd for Windows):\n",
    "- **activate rasa**\n",
    "- come to directory where actions.py is and then run\n",
    "- **python -m rasa_core_sdk.endpoint --actions actions**\n",
    "\n",
    "This way, custom action server starts ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# python = sys.executable\n",
    "# !{python} -m rasa_core_sdk.endpoint --actions actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M-jn1g_k-o-m"
   },
   "source": [
    "###  Visualising the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1090
    },
    "colab_type": "code",
    "id": "O1gYRXe15amU",
    "outputId": "9c0838e3-56c1-4eeb-a879-cc09619269d3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yogesh.kulkarni\\AppData\\Local\\Continuum\\anaconda3\\envs\\rasa\\lib\\site-packages\\rasa\\core\\policies\\keras_policy.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'story_graph.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-57f1a1c44d16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'config/domain.yml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/stories.md\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"story_graph.png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_history\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"story_graph.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\rasa\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[0;32m   1195\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         super(Image, self).__init__(data=data, url=url, filename=filename, \n\u001b[1;32m-> 1197\u001b[1;33m                 metadata=metadata)\n\u001b[0m\u001b[0;32m   1198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1199\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'width'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\rasa\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\rasa\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36mreload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1226\u001b[0m         \u001b[1;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1227\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1228\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1229\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1230\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\rasa\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36mreload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'story_graph.png'"
     ]
    }
   ],
   "source": [
    "\n",
    "from IPython.display import Image, display\n",
    "from rasa_core.agent import Agent\n",
    "%matplotlib inline\n",
    "\n",
    "agent = Agent('config/domain.yml')\n",
    "agent.visualize(\"data/stories.md\", \"story_graph.png\", max_history=2)\n",
    "i = Image(filename=\"story_graph.png\")\n",
    "display(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCdKD3l7-ua8"
   },
   "source": [
    "### Training a Dialogue Model\n",
    "\n",
    "You can train the model using the following command:\n",
    "\n",
    "**python -m rasa_core.train -d domain.yml -s data/stories.md -o models/current/dialogue -c policies.yml**\n",
    "\n",
    "Or do it programmatically as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7364
    },
    "colab_type": "code",
    "id": "4D7R-FRO5dxz",
    "outputId": "727adf2a-fa4b-4158-df94-30ad472f62f3"
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from rasa_core.policies import FallbackPolicy, KerasPolicy, MemoizationPolicy, MappingPolicy\n",
    "from rasa_core.agent import Agent\n",
    "\n",
    "# this will catch predictions the model isn't very certain about\n",
    "# there is a threshold for the NLU predictions as well as the action predictions\n",
    "fallback = FallbackPolicy(fallback_action_name=\"utter_unclear\",\n",
    "                          core_threshold=0.2,\n",
    "                          nlu_threshold=0.1)\n",
    "\n",
    "# agent = Agent('domain.yml', policies=[MemoizationPolicy(), KerasPolicy(), fallback])\n",
    "\n",
    "agent = Agent('config/domain.yml', policies = [MemoizationPolicy(max_history=2), KerasPolicy(validation_split=0.2,epochs=200),MappingPolicy()])\n",
    "# loop = asyncio.get_event_loop() # https://github.com/RasaHQ/rasa/issues/3649\n",
    "# training_data = loop.run_until_complete(agent.load_data('data/stories.md'))\n",
    "training_data = await agent.load_data('data/stories.md') # https://forum.rasa.com/t/call-agent-train-occurs-typeerror-coroutine-object-is-not-iterable/10135/10\n",
    "# loading our neatly defined training dialogues\n",
    "# training_data = agent.load_data('data/stories.md')\n",
    "\n",
    "agent.train(training_data)\n",
    "# FOLLOWING WAY OF giving arguments is depreacted, instead, give these params as arguments to KerasPolicy\n",
    "# agent.train(\n",
    "#     training_data,\n",
    "#     validation_split=0.0,\n",
    "#     epochs=200\n",
    "# )\n",
    "\n",
    "agent.persist('models/current/dialogue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4911z6y-5rD"
   },
   "source": [
    "## Running: Talk to your Bot\n",
    "\n",
    "So we have the chatbot ready. It’s time to chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way is to run following command in shell (windows cmd)\n",
    "- activate the environment,\n",
    "- come to directory where actions.py is and then run\n",
    "- **python -m rasa_core.run -d models/current/dialogue -u models/current/nlu --endpoints endpoints.yml**\n",
    "\n",
    "Or else do programmatically like below\n",
    "\n",
    "Both approaches expect rasa core sdk server running in a separate window, else **python -m rasa_core_sdk.endpoint --actions actions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nE4coPam5hry",
    "outputId": "c8ec135b-882b-4e9e-a955-f3e184177817"
   },
   "outputs": [],
   "source": [
    "# #Starting the Bot\n",
    "\n",
    "import IPython\n",
    "from IPython.display import clear_output\n",
    "from rasa_core.agent import Agent\n",
    "from rasa_core.interpreter import NaturalLanguageInterpreter\n",
    "# from rasa_core.utils import EndpointConfig\n",
    "from rasa.utils.endpoints import EndpointConfig\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "def load_assistant():\n",
    "    messages = [\"Hi! you can chat in this window. Type 'stop' to end the conversation.\"]\n",
    "    model_dir = 'models/nlu/current' # or model_directory defined earlier\n",
    "    interpreter = NaturalLanguageInterpreter.create(model_dir)\n",
    "    endpoint = EndpointConfig('http://localhost:5055/webhook')\n",
    "    agent = Agent.load('models/current/dialogue', interpreter=interpreter, action_endpoint = endpoint)\n",
    "\n",
    "    print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "    while True:\n",
    "        a = input()\n",
    "        if a == 'stop':\n",
    "            break\n",
    "        responses = asyncio.run(agent.handle_text(a)) # For Python 3.7\n",
    "#         responses = agent.handle_text(a)\n",
    "        for response in responses:\n",
    "            print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "DDVLzhAT5yrP",
    "outputId": "aee3fc83-df97-42b4-c7e0-c8929f76337c"
   },
   "outputs": [],
   "source": [
    "load_assistant()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "enJNkbvB54y1"
   },
   "source": [
    "## What Next?\n",
    "\n",
    "- Try to use different pipelines in Rasa Core, explore more Policies, fine-tune those models, \n",
    "- Check out what other features CricAPI provides, etc.\n",
    "- Other APIs\n",
    "- Slot filling\n",
    "- Different languages (Hindi bot?)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "include_colab_link": true,
   "name": "Conversational_Chatbot.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:rasa] *",
   "language": "python",
   "name": "conda-env-rasa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
