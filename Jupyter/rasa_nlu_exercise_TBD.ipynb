{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3oxVq6vQ76r7"
   },
   "source": [
    "# IPL Chatbot\n",
    "\n",
    "Original: Learn how to Build and Deploy a Chatbot in Minutes using Rasa (IPL Case Study!) - Mohd Sanad Zaki Rizvi, Analytics Vidhya https://www.analyticsvidhya.com/blog/2019/04/learn-build-chatbot-rasa-nlp-ipl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kIFYA-Kp8aK4"
   },
   "source": [
    "**Objectives** To build a chatbot capable of fetching latest info about the ongoing IPL (Indian Premier League) matches from cricapi.com site.\n",
    "\n",
    "<img src=\"images/ipl.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rasa Stack\n",
    "\n",
    "- Lets you focus on improving the “Chatbot” part of your project \n",
    "- Default set up of Rasa works really well right out of the box for intent extraction and dialogue management\n",
    "- LOCAL models, no API calls for intent extraction and dialogue management, except if your business logic needs external calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture of chatbot\n",
    "\n",
    "<img src=\"images/rasa_full4.png\">\n",
    "\n",
    "\n",
    "- As soon as Rasa receives a message from the end user, it tries to predict or extract the “intent” and “entities” present in the message. This part is handled by Rasa NLU\n",
    "- Once the user’s intent is identified, the Rasa Stack performs an action called action_match_news to get the updates from the latest IPL match\n",
    "- Rasa then tries to predict what it should do next. This decision is taken considering multiple factors and is handled by Rasa Core\n",
    "- In this example, Rasa is showing the result of the most recent match to the user. It has also predicted the next action that our model should take – to check with the user whether the chatbot was able to solve his/her query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IVAF41hr8jU5"
   },
   "source": [
    "## Installations\n",
    "Official Documentation: https://rasa.com/docs/core/installation/\n",
    "* Python\n",
    "* Rasa Starter Pack\n",
    "* Spacy Language Model\n",
    "\n",
    "\n",
    "### Python\n",
    "* Install Anaconda 4.2.0 for Python 3.5 or Ananconda 5.2.0 for Python 3.6 \n",
    "* Windows Build tools: Make sure the Microsoft $VC++$ Compiler Visual Studio 2015 is installed, so python can compile any dependencies or https://visualstudio.microsoft.com/visual-cpp-build-tools/ Download the installer and select VC++ Build tools in the list.\n",
    "\n",
    "(My Note: on main page of Anaconda is https://www.anaconda.com/distribution/ you see Python 3.7, which is problematic, gives HTTP error while creating env. I had to delete 3.7 and get 3.6. Btw, this site does not mention which Anaconda installer has which Python version. WHY? thats the most crucial info. Anyway, I have given them here.)\n",
    "\n",
    "### Python Environment\n",
    "* By installing conda, you get base or the root environment, which is the default.\n",
    "* Practical tip: DO NOT install any packages in the root. ALWAYS create and env and install inside the new env.\n",
    "* Env is needed esepcially for fragile packages like Python (its treated as a package) and rasa.\n",
    "* So, **conda create -n rasa python=3.6** \n",
    "\n",
    "(My Note: Env management is again a sour point. It creates complete copy (deeeep) of python 3.6 and all other packages inside \"envs\" folder. Goes to 1.5 GB!! Can someone optimize it?)\n",
    "\n",
    "\n",
    "### IPL bot code (for reference)\n",
    "\n",
    "* Clone repo from https://github.com/mohdsanadzakirizvi/iplbot.git\n",
    "* \"Complete Version\" gives latest running application (Some modifications are needed, mentioned below)\n",
    "\n",
    "<!---\n",
    "* Let’s take a look at the folder structure and the files that were created \n",
    "<img src=\"images/nlu.png\">\n",
    "* Install git, can git clone above package.\n",
    "-->\n",
    "\n",
    "* **WE WILL BE CODING IT FROM SCRATCH**\n",
    "* Run following commands:\n",
    "\n",
    "* **mkdir code; cd code;mkdir data**\n",
    "* **activate rasa**\n",
    "* **pip install -r iplbot_requirements.txt** or **conda env create -f environment.yml**\n",
    "\n",
    "\n",
    "### Spacy Language Models\n",
    "* Open cmd in Administrator mode and activate the env\n",
    "* Download medium english by **python -m spacy download en_core_web_md** \n",
    "* Link with **python -m spacy link en_core_web_md en --force**\n",
    "\n",
    "\n",
    "(My Note: First command will show that linking is done, but it may not have happened actually. So, do next step anyway.)\n",
    "\n",
    "### Others\n",
    "* Install nb_conda_kernels to let Jupyter Notebook see the new env\n",
    "* Create account on cricapi.com (free, can login using Google account). Note down API Key and set it as CRICINFOAPI env variable\n",
    "\n",
    "<!---\n",
    "* Need Rasa Core SDK for custom actions **pip install rasa_core_sdk** and run it as **python -m rasa_core_sdk.endpoint --actions actions** where actions.py has all the custom actions\n",
    "* Install pygraphviz by **conda install -c alubbock pygraphviz**\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yHYeAA859JGq"
   },
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TSw6zFmk3iPu",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import logging, io, json, warnings\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import rasa_nlu\n",
    "import rasa_core\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEw5vhSq9gWa"
   },
   "source": [
    "## Rasa NLU: Extracting User Intent from a Message\n",
    "\n",
    "The first thing we want to do is figure out the intent of the user. What does he or she want to accomplish? Let’s utilize Rasa and build an NLU model to identify user intent and its related entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oDEAOmaI9o4a"
   },
   "source": [
    "### Preparing the NLU Training Data\n",
    "\n",
    "Training data for extracting the user intent.\n",
    "As you can see, the format of training data for ‘intent’ is quite simple in Rasa. You just have to:\n",
    "\n",
    "- Start the line with “## intent:intent_name”\n",
    "- Supply all the examples in the following lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RPxeQ1_14CjK",
    "outputId": "bfb5974f-f8ea-46b8-b8cb-9dd4479ed9cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'nlu_md' (str) to file 'data/nlu_data.md'.\n"
     ]
    }
   ],
   "source": [
    "nlu_md = \"\"\"\n",
    "## intent:goodbye  \n",
    "- Bye \n",
    "- Goodbye\n",
    "- See you later\n",
    "- Bye bot\n",
    "- Goodbye friend\n",
    "- bye\n",
    "- bye for now\n",
    "- catch you later\n",
    "- gotta go\n",
    "- See you\n",
    "- goodnight\n",
    "- have a nice day\n",
    "- i'm off\n",
    "- see you later alligator\n",
    "- we'll speak soon\n",
    "- end\n",
    "- finish\n",
    "\n",
    "## intent:greet\n",
    "- Hi\n",
    "- Hey\n",
    "- Hi bot\n",
    "- Hey bot\n",
    "- Hello\n",
    "- Good morning\n",
    "- hi again\n",
    "- hi folks\n",
    "- hi Mister\n",
    "- hi pal!\n",
    "- hi there\n",
    "- greetings\n",
    "- hello everybody\n",
    "- hello is anybody there\n",
    "- hello robot\n",
    "- who are you?\n",
    "- what are you?\n",
    "- what's up\n",
    "- how do you do?\n",
    "\n",
    "## intent:thanks\n",
    "- Thanks\n",
    "- Thank you\n",
    "- Thank you so much\n",
    "- Thanks bot\n",
    "- Thanks for that\n",
    "- cheers\n",
    "- cheers bro\n",
    "- ok thanks!\n",
    "- perfect thank you\n",
    "- thanks a bunch for everything\n",
    "- thanks for the help\n",
    "- thanks a lot\n",
    "- amazing, thanks\n",
    "- cool, thanks\n",
    "- cool thank you\n",
    "\n",
    "## intent:affirm\n",
    "- y\n",
    "- Y\n",
    "- yes\n",
    "- yes sure\n",
    "- absolutely\n",
    "- for sure\n",
    "- yes yes yes\n",
    "- definitely\n",
    "- yes, it did.\n",
    "\n",
    "## intent:current_matches\n",
    "- what are the current matches\n",
    "- can you list the matches in ipl 2019\n",
    "- which cricket match is happening right now\n",
    "- which ipl match is next\n",
    "- which teams are playing next in ipl\n",
    "- which team will play next in ipl\n",
    "- tell me some ipl news\n",
    "- i want ipl updates\n",
    "- can you give me ipl latest updates\n",
    "- what are the latest match updates\n",
    "- who won the last ipl match\n",
    "- which teams are competing in the next match\n",
    "- how is ipl going\n",
    "- what was the result of the last match\n",
    "- when is the next match\n",
    "\n",
    "## intent:deny\n",
    "- no\n",
    "- never\n",
    "- I don't think so\n",
    "- don't like that\n",
    "- no way\n",
    "- not really\n",
    "- n\n",
    "- N\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > data/nlu_data.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can include as many examples as you want for each intent. In fact, make sure to include slangs and short forms that you use while texting. The idea is to make the chatbot understand the way we type text. Feel free to refer to the complete version where I have given plenty of examples for each intent type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ceazcacn9veB"
   },
   "source": [
    "### Defining the NLU Model Configuration\n",
    "\n",
    "This file lets us create a text processing pipeline in Rasa. Luckily for us, Rasa comes with two default settings based on the amount of training data we have:\n",
    "- “spacy_sklearn” pipeline if you have less than 1000 training examples\n",
    "- “tensorflow_embedding” if you have a large amount of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dF60NWhR4ID6",
    "outputId": "92946645-94fc-4450-aa41-eca8895ff83c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'config' (str) to file 'config/nlu_config.yml'.\n"
     ]
    }
   ],
   "source": [
    "config = \"\"\"\n",
    "language: \"en\"\n",
    "pipeline: spacy_sklearn\n",
    "\"\"\" \n",
    "\n",
    "%store config > config/nlu_config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ieoWk91X9y8X"
   },
   "source": [
    "### Training the NLU Classifier Model\n",
    "\n",
    "On command line you can run following command:\n",
    "\n",
    "**python -m rasa_nlu.train -c nlu_config.yml --data data/nlu_data.md -o models --fixed_model_name nlu --project current --verbose**\n",
    "\n",
    "Or programmatically you can write code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "dp3AIHmS4L6x",
    "outputId": "8011c4f7-c789-4138-84d7-4710207615d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\YogeshKulkarni\\AppData\\Local\\conda\\conda\\envs\\rasa\\lib\\site-packages\\tensor2tensor\\utils\\adafactor.py:27: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\YogeshKulkarni\\AppData\\Local\\conda\\conda\\envs\\rasa\\lib\\site-packages\\tensor2tensor\\utils\\multistep_optimizer.py:32: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\YogeshKulkarni\\AppData\\Local\\conda\\conda\\envs\\rasa\\lib\\site-packages\\mesh_tensorflow\\ops.py:4237: The name tf.train.CheckpointSaverListener is deprecated. Please use tf.estimator.CheckpointSaverListener instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\YogeshKulkarni\\AppData\\Local\\conda\\conda\\envs\\rasa\\lib\\site-packages\\mesh_tensorflow\\ops.py:4260: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\YogeshKulkarni\\AppData\\Local\\conda\\conda\\envs\\rasa\\lib\\site-packages\\tensor2tensor\\models\\research\\neural_stack.py:51: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.\n",
      "\n",
      "INFO:absl:Entry Point [tensor2tensor.envs.tic_tac_toe_env:TicTacToeEnv] registered with id [T2TEnv-TicTacToeEnv-v0]\n",
      "WARNING:tensorflow:From C:\\Users\\YogeshKulkarni\\AppData\\Local\\conda\\conda\\envs\\rasa\\lib\\site-packages\\tensor2tensor\\utils\\trainer_lib.py:111: The name tf.OptimizerOptions is deprecated. Please use tf.compat.v1.OptimizerOptions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\YogeshKulkarni\\AppData\\Local\\conda\\conda\\envs\\rasa\\lib\\site-packages\\tensorflow_gan\\python\\contrib_utils.py:305: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\YogeshKulkarni\\AppData\\Local\\conda\\conda\\envs\\rasa\\lib\\site-packages\\tensorflow_gan\\python\\contrib_utils.py:310: The name tf.estimator.tpu.TPUEstimatorSpec is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimatorSpec instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\YogeshKulkarni\\AppData\\Local\\conda\\conda\\envs\\rasa\\lib\\site-packages\\rasa\\utils\\train_utils.py:28: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:rasa_nlu.config:You have specified the pipeline template 'spacy_sklearn' which has been renamed to 'pretrained_embeddings_spacy'. Please update your code as it will no longer work with future versions of Rasa NLU.\n",
      "INFO:rasa.nlu.utils.spacy_utils:Trying to load spacy model with name 'en'\n",
      "INFO:rasa.nlu.components:Added 'SpacyNLP' to component cache. Key 'SpacyNLP-en'.\n",
      "INFO:rasa_nlu.model:Starting to train component SpacyNLP\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component SpacyTokenizer\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component SpacyFeaturizer\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component RegexFeaturizer\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component CRFEntityExtractor\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component EntitySynonymMapper\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component SklearnIntentClassifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.0s finished\n",
      "C:\\Users\\YogeshKulkarni\\AppData\\Local\\conda\\conda\\envs\\rasa\\lib\\site-packages\\sklearn\\model_selection\\_search.py:842: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Successfully saved model into 'D:\\Yogesh\\ToDos\\Teaching\\TeachingDataScience\\Jupyter\\models\\nlu\\current'\n"
     ]
    }
   ],
   "source": [
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu.config import RasaNLUModelConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "from rasa_nlu import config\n",
    "\n",
    "# loading the nlu training samples\n",
    "training_data = load_data(\"data/nlu_data.md\")\n",
    "\n",
    "# trainer to educate our pipeline\n",
    "trainer = Trainer(config.load(\"config/nlu_config.yml\"))\n",
    "\n",
    "# train the model!\n",
    "interpreter = trainer.train(training_data)\n",
    "\n",
    "# store it for future use\n",
    "model_directory = trainer.persist(\"./models/nlu\", fixed_model_name=\"current\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jrfp4xOS95ZZ"
   },
   "source": [
    "### Evaluating the NLU model on a random text (first way)\n",
    "\n",
    "Let’s test how good our model is performing by giving it a sample text that it hasn’t been trained on for extracting intent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "4UjzlqMV4N1k",
    "outputId": "37ea93e5-6a71-4e8e-d2b6-a45144d184ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"current_matches\",\n",
      "    \"confidence\": 0.5398919216672282\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"current_matches\",\n",
      "      \"confidence\": 0.5398919216672282\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.258883611593913\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.08764150338897336\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.05091891706981237\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.032140384032668654\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thanks\",\n",
      "      \"confidence\": 0.030523662247404274\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"what is happening in the cricket world these days?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# A helper function for prettier output\n",
    "\n",
    "def pprint(o):   \n",
    "    print(json.dumps(o, indent=2))\n",
    "    \n",
    "pprint(interpreter.parse(\"what is happening in the cricket world these days?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only does our NLU model perform well on intent extraction, but it also ranks the other intents based on their confidence scores. This is a nifty little feature that can be really useful when the classifier is confused between multiple intents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the NLU model on a random text (2nd way)\n",
    "Let’s test how good our model is performing by giving it a sample text that it hasn’t been trained on for extracting intent. You can open an iPython/Python shell and follow the following steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa.nlu.components:Added 'SpacyNLP' to component cache. Key 'SpacyNLP-en'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'intent': {'name': 'current_matches', 'confidence': 0.5398919216672282},\n",
       " 'entities': [],\n",
       " 'intent_ranking': [{'name': 'current_matches',\n",
       "   'confidence': 0.5398919216672282},\n",
       "  {'name': 'greet', 'confidence': 0.258883611593913},\n",
       "  {'name': 'goodbye', 'confidence': 0.08764150338897336},\n",
       "  {'name': 'affirm', 'confidence': 0.05091891706981237},\n",
       "  {'name': 'deny', 'confidence': 0.032140384032668654},\n",
       "  {'name': 'thanks', 'confidence': 0.030523662247404274}],\n",
       " 'text': 'what is happening in the cricket world these days?'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rasa_nlu.model import Interpreter\n",
    "nlu_model = Interpreter.load('./models/nlu/current')\n",
    "nlu_model.parse('what is happening in the cricket world these days?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OPlSd-As-Fz4"
   },
   "source": [
    "### Evaluating the NLU model on a test data\n",
    "(Here we are using the data at hand i.e nlu.md but it isr recommended to use unseen data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1483
    },
    "colab_type": "code",
    "id": "FmRCylbT4jyw",
    "outputId": "fd1bfd57-ebb3-4541-d3b3-b4cbba781164"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa.nlu.components:Added 'SpacyNLP' to component cache. Key 'SpacyNLP-en'.\n",
      "INFO:rasa_nlu.test:Running model for predictions:\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 83/83 [00:00<00:00, 258.79it/s]\n",
      "INFO:rasa_nlu.test:Intent evaluation results:\n",
      "INFO:rasa_nlu.test:Intent Evaluation: Only considering those 83 examples that have a defined intent out of 83 examples\n",
      "INFO:rasa_nlu.test:F1-Score:  1.0\n",
      "INFO:rasa_nlu.test:Precision: 1.0\n",
      "INFO:rasa_nlu.test:Accuracy:  1.0\n",
      "INFO:rasa_nlu.test:Classification report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           deny       1.00      1.00      1.00         8\n",
      "current_matches       1.00      1.00      1.00        15\n",
      "         thanks       1.00      1.00      1.00        15\n",
      "        goodbye       1.00      1.00      1.00        17\n",
      "         affirm       1.00      1.00      1.00         9\n",
      "          greet       1.00      1.00      1.00        19\n",
      "\n",
      "      micro avg       1.00      1.00      1.00        83\n",
      "      macro avg       1.00      1.00      1.00        83\n",
      "   weighted avg       1.00      1.00      1.00        83\n",
      "\n",
      "INFO:rasa_nlu.test:Entity evaluation results:\n",
      "INFO:rasa_nlu.test:Evaluation for entity extractor: CRFEntityExtractor \n",
      "WARNING:rasa_nlu.test:No labels to evaluate. Skip evaluation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'intent_evaluation': {'predictions': [{'text': 'Bye',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.9585333997253026},\n",
       "   {'text': 'Goodbye',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.8738052021877047},\n",
       "   {'text': 'See you later',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.784749061819731},\n",
       "   {'text': 'Bye bot',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.7992521352304371},\n",
       "   {'text': 'Goodbye friend',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.8169194572692575},\n",
       "   {'text': 'bye',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.9585333997253026},\n",
       "   {'text': 'bye for now',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.7526951795769953},\n",
       "   {'text': 'catch you later',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.7557877977441877},\n",
       "   {'text': 'gotta go',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.7908313653994801},\n",
       "   {'text': 'See you',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.7397197734813323},\n",
       "   {'text': 'goodnight',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.8738052021877047},\n",
       "   {'text': 'have a nice day',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.7211619385580803},\n",
       "   {'text': \"i'm off\",\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.7674678986327573},\n",
       "   {'text': 'see you later alligator',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.7582905018753555},\n",
       "   {'text': \"we'll speak soon\",\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.7490381818999119},\n",
       "   {'text': 'end',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.8067438258985427},\n",
       "   {'text': 'finish',\n",
       "    'intent': 'goodbye',\n",
       "    'predicted': 'goodbye',\n",
       "    'confidence': 0.8242264163393631},\n",
       "   {'text': 'Hi',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.9843737220354137},\n",
       "   {'text': 'Hey',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.8795247877944417},\n",
       "   {'text': 'Hi bot',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.8699828600011349},\n",
       "   {'text': 'Hey bot',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.7863667540950233},\n",
       "   {'text': 'Hello',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.9251053753417947},\n",
       "   {'text': 'Good morning',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.794883561692539},\n",
       "   {'text': 'hi again',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.8057630696551386},\n",
       "   {'text': 'hi folks',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.876164516127677},\n",
       "   {'text': 'hi Mister',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.9611584157864548},\n",
       "   {'text': 'hi pal!',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.8623357090319779},\n",
       "   {'text': 'hi there',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.873652815296685},\n",
       "   {'text': 'greetings',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.839858690005914},\n",
       "   {'text': 'hello everybody',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.8792722435096934},\n",
       "   {'text': 'hello is anybody there',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.7554926006406404},\n",
       "   {'text': 'hello robot',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.8391097131202984},\n",
       "   {'text': 'who are you?',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.7708333557262783},\n",
       "   {'text': 'what are you?',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.7984140580738107},\n",
       "   {'text': \"what's up\",\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.7580096947358804},\n",
       "   {'text': 'how do you do?',\n",
       "    'intent': 'greet',\n",
       "    'predicted': 'greet',\n",
       "    'confidence': 0.7835472874080653},\n",
       "   {'text': 'Thanks',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.9981030718043125},\n",
       "   {'text': 'Thank you',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.8862132510180118},\n",
       "   {'text': 'Thank you so much',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.7048296257295901},\n",
       "   {'text': 'Thanks bot',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.808598671102271},\n",
       "   {'text': 'Thanks for that',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.7450907520304664},\n",
       "   {'text': 'cheers',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.946297990473743},\n",
       "   {'text': 'cheers bro',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.8485021388675418},\n",
       "   {'text': 'ok thanks!',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.7967982407157338},\n",
       "   {'text': 'perfect thank you',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.7413063366807335},\n",
       "   {'text': 'thanks a bunch for everything',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.6947485595963936},\n",
       "   {'text': 'thanks for the help',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.7094695550848913},\n",
       "   {'text': 'thanks a lot',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.7931199095871139},\n",
       "   {'text': 'amazing, thanks',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.8673548270738479},\n",
       "   {'text': 'cool, thanks',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.7969833461278172},\n",
       "   {'text': 'cool thank you',\n",
       "    'intent': 'thanks',\n",
       "    'predicted': 'thanks',\n",
       "    'confidence': 0.8136667001569489},\n",
       "   {'text': 'y',\n",
       "    'intent': 'affirm',\n",
       "    'predicted': 'affirm',\n",
       "    'confidence': 0.8030139748118817},\n",
       "   {'text': 'Y',\n",
       "    'intent': 'affirm',\n",
       "    'predicted': 'affirm',\n",
       "    'confidence': 0.8030139748118817},\n",
       "   {'text': 'yes',\n",
       "    'intent': 'affirm',\n",
       "    'predicted': 'affirm',\n",
       "    'confidence': 0.8458793507116671},\n",
       "   {'text': 'yes sure',\n",
       "    'intent': 'affirm',\n",
       "    'predicted': 'affirm',\n",
       "    'confidence': 0.787805577124146},\n",
       "   {'text': 'absolutely',\n",
       "    'intent': 'affirm',\n",
       "    'predicted': 'affirm',\n",
       "    'confidence': 0.7914603951827934},\n",
       "   {'text': 'for sure',\n",
       "    'intent': 'affirm',\n",
       "    'predicted': 'affirm',\n",
       "    'confidence': 0.7466254423154497},\n",
       "   {'text': 'yes yes yes',\n",
       "    'intent': 'affirm',\n",
       "    'predicted': 'affirm',\n",
       "    'confidence': 0.8458793503920992},\n",
       "   {'text': 'definitely',\n",
       "    'intent': 'affirm',\n",
       "    'predicted': 'affirm',\n",
       "    'confidence': 0.7526340791429363},\n",
       "   {'text': 'yes, it did.',\n",
       "    'intent': 'affirm',\n",
       "    'predicted': 'affirm',\n",
       "    'confidence': 0.7639542297017925},\n",
       "   {'text': 'what are the current matches',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.7523699532311331},\n",
       "   {'text': 'can you list the matches in ipl 2019',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.8379510691462777},\n",
       "   {'text': 'which cricket match is happening right now',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.7711029469552962},\n",
       "   {'text': 'which ipl match is next',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.949634249704295},\n",
       "   {'text': 'which teams are playing next in ipl',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.83256661673822},\n",
       "   {'text': 'which team will play next in ipl',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.874084482601363},\n",
       "   {'text': 'tell me some ipl news',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.7501405989326569},\n",
       "   {'text': 'i want ipl updates',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.8012525104193058},\n",
       "   {'text': 'can you give me ipl latest updates',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.7340612872491206},\n",
       "   {'text': 'what are the latest match updates',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.8088379624430408},\n",
       "   {'text': 'who won the last ipl match',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.9313075895447416},\n",
       "   {'text': 'which teams are competing in the next match',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.7527785545087736},\n",
       "   {'text': 'how is ipl going',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.7712284507152787},\n",
       "   {'text': 'what was the result of the last match',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.7161096057087418},\n",
       "   {'text': 'when is the next match',\n",
       "    'intent': 'current_matches',\n",
       "    'predicted': 'current_matches',\n",
       "    'confidence': 0.74159995141299},\n",
       "   {'text': 'no',\n",
       "    'intent': 'deny',\n",
       "    'predicted': 'deny',\n",
       "    'confidence': 0.9098388960322983},\n",
       "   {'text': 'never',\n",
       "    'intent': 'deny',\n",
       "    'predicted': 'deny',\n",
       "    'confidence': 0.7750975711543211},\n",
       "   {'text': \"I don't think so\",\n",
       "    'intent': 'deny',\n",
       "    'predicted': 'deny',\n",
       "    'confidence': 0.6856396929903847},\n",
       "   {'text': \"don't like that\",\n",
       "    'intent': 'deny',\n",
       "    'predicted': 'deny',\n",
       "    'confidence': 0.6850472634703366},\n",
       "   {'text': 'no way',\n",
       "    'intent': 'deny',\n",
       "    'predicted': 'deny',\n",
       "    'confidence': 0.6798341109307839},\n",
       "   {'text': 'not really',\n",
       "    'intent': 'deny',\n",
       "    'predicted': 'deny',\n",
       "    'confidence': 0.7351057637012328},\n",
       "   {'text': 'n',\n",
       "    'intent': 'deny',\n",
       "    'predicted': 'deny',\n",
       "    'confidence': 0.675350867302557},\n",
       "   {'text': 'N',\n",
       "    'intent': 'deny',\n",
       "    'predicted': 'deny',\n",
       "    'confidence': 0.675350867302557}],\n",
       "  'report': '                 precision    recall  f1-score   support\\n\\n           deny       1.00      1.00      1.00         8\\ncurrent_matches       1.00      1.00      1.00        15\\n         thanks       1.00      1.00      1.00        15\\n        goodbye       1.00      1.00      1.00        17\\n         affirm       1.00      1.00      1.00         9\\n          greet       1.00      1.00      1.00        19\\n\\n      micro avg       1.00      1.00      1.00        83\\n      macro avg       1.00      1.00      1.00        83\\n   weighted avg       1.00      1.00      1.00        83\\n',\n",
       "  'precision': 1.0,\n",
       "  'f1_score': 1.0,\n",
       "  'accuracy': 1.0},\n",
       " 'entity_evaluation': {'CRFEntityExtractor': {'report': {},\n",
       "   'precision': 0.0,\n",
       "   'f1_score': 0.0,\n",
       "   'accuracy': 0.0}},\n",
       " 'response_selection_evaluation': None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rasa_nlu.test import run_evaluation\n",
    "\n",
    "run_evaluation(\"data/nlu_data.md\", model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Av3R2GZZ-WJO"
   },
   "source": [
    "## Rasa Core: Making Interactive Conversations\n",
    "\n",
    "One of the most important aspects of a chatbot application is its ability to be interactive. \n",
    "\n",
    "### Designing the conversational flow\n",
    "\n",
    "Think of the simplest conversation our chatbot can have with a user. What would be the flow of such a conversation?\n",
    "\n",
    "---\n",
    "Me: Hi\n",
    "\n",
    "Iplbot: Hey! How may I help you?\n",
    "\n",
    "Me: What was the result of the last match?\n",
    "\n",
    "Iplbot: Here are some IPL quick info:\n",
    "1.The match between Rajasthan Royals and Delhi Capitals was recently held and Delhi Capitals won.\n",
    "2.The next match is Warriors vs Titans on 22 April 2019\n",
    "\n",
    "Iplbot: Did that help you?\n",
    "\n",
    "Me: yes, thank you!\n",
    "\n",
    "Iplbot: Glad that I could help!\n",
    "\n",
    "---\n",
    "Let’s see how we can teach a simple conversation like that to Rasa:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## news path 1\n",
    "* greet\n",
    "  - utter_greet\n",
    "* current_matches\n",
    "  - action_match_news\n",
    "  - utter_did_that_help\n",
    "* affirm or thanks\n",
    "  - utter_gratitude\n",
    "* goodbye\n",
    "  - utter_goodbye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general format is:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## news path 1           <--- story name for debugging purposes\n",
    "* greet                  <--- intent detected from the user\n",
    "  - utter_greet          <--- what action the bot should take\n",
    "* current_matches        <--- the following intent in the conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is called a user story path. I have provided a few stories in the data/stories.md file for your reference. This is the training data for Rasa Core."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BKZ63AuS-ZPV"
   },
   "source": [
    "### Writing  Stories\n",
    "\n",
    "The way it works is:\n",
    "\n",
    "- Give some examples of sample story paths that the user is expected to follow\n",
    "- Rasa Core combines them randomly to create more complex user paths\n",
    "- It then builds a probabilistic model out of that. This model is used to predict the next action Rasa should take\n",
    "\n",
    "<img src=\"images/conversation_flow.png\">\n",
    "\n",
    "The above illustration might look complicated, but it’s simply listing out various possible user stories that I have taught Rasa. Here are a few things to note from the above graph:\n",
    "\n",
    "- Except for the START and END boxes, all the colored boxes indicate user intent\n",
    "- All the white boxes are actions that the chatbot performs\n",
    "- Arrows indicate the flow of the conversation\n",
    "- action_match_news is where we hit the CricAPI to get IPL information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W3q1XJ5O4orY",
    "outputId": "a82511c7-b7e5-462c-c5c2-35df3cabd39a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'stories_md' (str) to file 'data/stories.md'.\n"
     ]
    }
   ],
   "source": [
    "stories_md = \"\"\"\n",
    "## news path 1\n",
    "* greet\n",
    "  - utter_greet\n",
    "* current_matches\n",
    "  - action_match_news\n",
    "  - utter_did_that_help\n",
    "* affirm or thanks\n",
    "  - utter_gratitude\n",
    "* goodbye\n",
    "  - utter_goodbye\n",
    "\n",
    "## news path 2\n",
    "* current_matches\n",
    "  - action_match_news\n",
    "  - utter_did_that_help\n",
    "* affirm or thanks\n",
    "  - utter_gratitude\n",
    "* goodbye\n",
    "  - utter_goodbye\n",
    "\n",
    "## news path 3\n",
    "* greet\n",
    "  - utter_greet\n",
    "* current_matches\n",
    "  - action_match_news\n",
    "  - utter_did_that_help\n",
    "* deny\n",
    "  - utter_ask_again\n",
    "* current_matches\n",
    "  - action_match_news\n",
    "  - utter_did_that_help\n",
    "* affirm or thanks\n",
    "  - utter_gratitude\n",
    "* goodbye\n",
    "  - utter_goodbye\n",
    "\n",
    "## greet path\n",
    "* greet\n",
    "  - utter_greet\n",
    "\n",
    "## goodbye path\n",
    "* goodbye\n",
    "  - utter_goodbye\n",
    "\"\"\"\n",
    "\n",
    "%store stories_md > data/stories.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, generate a similar graph for your stories using the following command:\n",
    "\n",
    "**python -m rasa_core.visualize -d domain.yml -s data/stories.md -o graph.html**\n",
    "\n",
    "This is very helpful when debugging the conversational flow of the chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LnD9v_CX-ePm"
   },
   "source": [
    "### Defining the Domain\n",
    "\n",
    "The domain is the world of your chatbot. It contains everything the chatbot should know, including:\n",
    "\n",
    "- All the actions it is capable of doing\n",
    "- The intents it should understand\n",
    "- The template of all the utterances it should tell the user, and much more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3SzQq1oy5U9T",
    "outputId": "4fde8c0d-9672-457c-cacc-0e86d3ca5c80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'domain_yml' (str) to file 'config/domain.yml'.\n"
     ]
    }
   ],
   "source": [
    "domain_yml = \"\"\"\n",
    "actions:\n",
    "- utter_greet\n",
    "- utter_did_that_help\n",
    "- utter_goodbye\n",
    "- action_match_news\n",
    "- utter_default\n",
    "- utter_gratitude\n",
    "- utter_ask_again\n",
    "\n",
    "intents:\n",
    "- goodbye\n",
    "- greet\n",
    "- thanks\n",
    "- current_matches\n",
    "- affirm\n",
    "- deny\n",
    "\n",
    "templates:\n",
    "  utter_greet:\n",
    "  - text: \"Hey! What can I do for you?\"\n",
    "  utter_did_that_help:\n",
    "  - text: \"Did that help you?\"\n",
    "  - text: \"I hope that solved your query\"\n",
    "  utter_goodbye:\n",
    "  - text: \"Bye\"\n",
    "  utter_default:\n",
    "  - text: \"I am sorry, I didn't get that. Could you please repeat your query?\"\n",
    "  - text: \"I am not sure what you are aiming for.\"\n",
    "  utter_gratitude:\n",
    "  - text: \"Glad that I could be of help to you!\\nBye\"\n",
    "  utter_ask_again:\n",
    "  - text: \"Okay! Let's start again, please tell me what do you need?\"\n",
    "  - text: \"No issues! Let's try this again.\\n Please repeat your query?\"\n",
    "\"\"\"\n",
    "\n",
    "%store domain_yml > config/domain.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Policies\n",
    "\n",
    "Rasa Core generates the training data for the conversational part using the stories we provide. It also lets you define a set of policies to use when deciding the next action of the chatbot. These policies are defined in the policies.yml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'policies_yml' (str) to file 'config/policies.yml'.\n"
     ]
    }
   ],
   "source": [
    "policies_yml = \"\"\"\n",
    "policies:\n",
    "  - name: KerasPolicy\n",
    "    epochs: 100\n",
    "    max_history: 5\n",
    "  - name: FallbackPolicy\n",
    "    fallback_action_name: 'action_default_fallback'\n",
    "  - name: MemoizationPolicy\n",
    "    max_history: 5\n",
    "\"\"\"\n",
    "\n",
    "%store policies_yml > config/policies.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- KerasPolicy uses a neural network implemented in Keras to select the next action. The default architecture is based on an LSTM (Long Short Term Memory) model\n",
    "- MemoizationPolicy memorizes the conversations in your training data. It predicts the next action with confidence 1.0 if this exact conversation exists in the training data, otherwise, it predicts ‘None’ with confidence 0.0\n",
    "- FallbackPolicy invokes a fallback action if the intent recognition has confidence below nlu_threshold or if none of the dialogue policies predict action with confidence higher than core_threshold\n",
    "- One important hyperparameter for Rasa Core policies is the max_history. This controls how much dialogue history the model looks at to decide which action to take next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ROL3AYs5-iCg"
   },
   "source": [
    "###  Custom Actions\n",
    "\n",
    "Using CricAPI for fetching IPL related news. It is free for 100 requests per day, which (I hope) is more than enough to satiate that cricket crazy passion you have.\n",
    "\n",
    "You need to first signup on the website to get access to their API:\n",
    "https://www.cricapi.com/\n",
    "\n",
    "You should be able to see your API Key once you are logged in:\n",
    "\n",
    "<img src=\"images/lala-1140x399.png\">\n",
    "\n",
    "Modifications to original code:\n",
    "\n",
    "- Instead of showing API key here it has been stored in ENV variable and fetched here\n",
    "- Key \"toss_winner_team\" was subsituted into depreceated key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7SbmLMJa5X0E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'actions_py' (str) to file 'actions.py'.\n"
     ]
    }
   ],
   "source": [
    "actions_py=\"\"\"\n",
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "from datetime import datetime\n",
    "\n",
    "import logging\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from rasa_core_sdk import Action\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "API_URL = \"https://cricapi.com/api/\"\n",
    "API_KEY = os.environ.get('CRICINFOAPI')\n",
    "\n",
    "class ApiAction(Action):\n",
    "    def name(self):\n",
    "        return \"action_match_news\"\n",
    "\n",
    "    def run(self, dispatcher, tracker, domain):\n",
    "        print(API_URL + \"matches\" + \"?apikey=\" + API_KEY)\n",
    "        res = requests.get(API_URL + \"matches\" + \"?apikey=\" + API_KEY) #, verify=False\n",
    "        if res.status_code == 200:\n",
    "            data = res.json()[\"matches\"]\n",
    "            recent_match = data[0]\n",
    "            upcoming_match = data[1]\n",
    "            upcoming_match[\"date\"] = datetime.strptime(upcoming_match[\"date\"], \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "            next_date = upcoming_match[\"date\"].strftime(\"%d %B %Y\")\n",
    "\n",
    "            out_message = \"Here some IPL quick info: 1.The match between {} and {} was recently held and {} won the toss.\".format(recent_match[\"team-1\"], recent_match[\"team-2\"], recent_match[\"toss_winner_team\"])\n",
    "\n",
    "            dispatcher.utter_message(out_message)\n",
    "\n",
    "            out_message = \"2.The next match is {} vs {} on {}\".format(upcoming_match[\"team-1\"], upcoming_match[\"team-2\"], next_date)\n",
    "\n",
    "            dispatcher.utter_message(out_message)\n",
    "\n",
    "            return []\n",
    "\"\"\"\n",
    "%store actions_py > actions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need endpoints yml to execute the actions server.\n",
    "\n",
    "Note: If you have external API call, like REST, need to have \"webhook\" word at the end, else nothing.\n",
    "\n",
    "My own query on this topic: https://forum.rasa.com/t/rasa-core-sdk-not-working/9228"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'endpoints_yml' (str) to file 'endpoints.yml'.\n"
     ]
    }
   ],
   "source": [
    "endpoints_yml = \"\"\"\n",
    "#action_endpoint:\n",
    "#  url: \"http://localhost:5055/webhook\"\n",
    "  \n",
    "action_endpoint:\n",
    "  url: http://localhost:5055/webhook\n",
    "\n",
    "#nlg:\n",
    "#  url: http://localhost:5056/nlg\n",
    "\n",
    "core_endpoint:\n",
    "  url: http://localhost:5005\n",
    "\"\"\"\n",
    "%store endpoints_yml > endpoints.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a separate shell (cmd for Windows):\n",
    "- **activate rasa**\n",
    "- come to directory where actions.py is and then run\n",
    "- **python -m rasa_core_sdk.endpoint --actions actions**\n",
    "\n",
    "This way, custom action server starts ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# python = sys.executable\n",
    "# !{python} -m rasa_core_sdk.endpoint --actions actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M-jn1g_k-o-m"
   },
   "source": [
    "###  Visualising the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1090
    },
    "colab_type": "code",
    "id": "O1gYRXe15amU",
    "outputId": "9c0838e3-56c1-4eeb-a879-cc09619269d3"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'story_graph.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-57f1a1c44d16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'config/domain.yml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/stories.md\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"story_graph.png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_history\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"story_graph.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\rasa\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[0;32m   1195\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         super(Image, self).__init__(data=data, url=url, filename=filename, \n\u001b[1;32m-> 1197\u001b[1;33m                 metadata=metadata)\n\u001b[0m\u001b[0;32m   1198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1199\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'width'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\rasa\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\rasa\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36mreload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1226\u001b[0m         \u001b[1;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1227\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1228\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1229\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1230\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\rasa\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36mreload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'story_graph.png'"
     ]
    }
   ],
   "source": [
    "\n",
    "from IPython.display import Image, display\n",
    "from rasa_core.agent import Agent\n",
    "%matplotlib inline\n",
    "\n",
    "agent = Agent('config/domain.yml')\n",
    "agent.visualize(\"data/stories.md\", \"story_graph.png\", max_history=2)\n",
    "i = Image(filename=\"story_graph.png\")\n",
    "display(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCdKD3l7-ua8"
   },
   "source": [
    "### Training a Dialogue Model\n",
    "\n",
    "You can train the model using the following command:\n",
    "\n",
    "**python -m rasa_core.train -d domain.yml -s data/stories.md -o models/current/dialogue -c policies.yml**\n",
    "\n",
    "Or do it programmatically as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7364
    },
    "colab_type": "code",
    "id": "4D7R-FRO5dxz",
    "outputId": "727adf2a-fa4b-4158-df94-30ad472f62f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:rasa.core.training.dsl:Found unknown intent 'affirm or thanks' on line 8. Please, make sure that all intents are listed in your domain yaml.\n",
      "WARNING:rasa.core.training.dsl:Found unknown intent 'affirm or thanks' on line 17. Please, make sure that all intents are listed in your domain yaml.\n",
      "WARNING:rasa.core.training.dsl:Found unknown intent 'affirm or thanks' on line 33. Please, make sure that all intents are listed in your domain yaml.\n",
      "Processed Story Blocks: 100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 1009.36it/s, # trackers=1]\n",
      "Processed Story Blocks: 100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 1002.61it/s, # trackers=3]\n",
      "Processed Story Blocks: 100%|█████████████████████████████████████████████| 5/5 [00:00<00:00, 455.80it/s, # trackers=9]\n",
      "Processed Story Blocks: 100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 294.89it/s, # trackers=16]\n",
      "Processed trackers: 100%|█████████████████████████████████████████████████| 5/5 [00:00<00:00, 135.49it/s, # actions=15]\n",
      "Processed actions: 15it [00:00, 1157.01it/s, # examples=15]\n",
      "Processed trackers: 100%|█████████████████████████████████████████████| 121/121 [00:01<00:00, 103.08it/s, # actions=64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (None, 5, 21)             0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                6912      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 15)                495       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 15)                0         \n",
      "=================================================================\n",
      "Total params: 7,407\n",
      "Trainable params: 7,407\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa.core.policies.keras_policy:Fitting model with 64 total samples and a validation split of 0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.7082 - acc: 0.156 - 0s 5ms/sample - loss: 2.6752 - acc: 0.1875\n",
      "Epoch 2/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.6703 - acc: 0.250 - 0s 171us/sample - loss: 2.6521 - acc: 0.2344\n",
      "Epoch 3/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.6162 - acc: 0.343 - 0s 187us/sample - loss: 2.6043 - acc: 0.2812\n",
      "Epoch 4/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.6018 - acc: 0.343 - 0s 171us/sample - loss: 2.5812 - acc: 0.3125\n",
      "Epoch 5/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.5892 - acc: 0.250 - 0s 187us/sample - loss: 2.5596 - acc: 0.2656\n",
      "Epoch 6/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.5486 - acc: 0.406 - 0s 187us/sample - loss: 2.5270 - acc: 0.3594\n",
      "Epoch 7/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.5618 - acc: 0.281 - 0s 156us/sample - loss: 2.5232 - acc: 0.2969\n",
      "Epoch 8/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.5079 - acc: 0.343 - 0s 187us/sample - loss: 2.4904 - acc: 0.3281\n",
      "Epoch 9/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.4440 - acc: 0.437 - 0s 156us/sample - loss: 2.4285 - acc: 0.3750\n",
      "Epoch 10/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.4222 - acc: 0.406 - 0s 156us/sample - loss: 2.4189 - acc: 0.3594\n",
      "Epoch 11/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.3969 - acc: 0.406 - 0s 156us/sample - loss: 2.3680 - acc: 0.3594\n",
      "Epoch 12/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.3508 - acc: 0.406 - 0s 171us/sample - loss: 2.3388 - acc: 0.3594\n",
      "Epoch 13/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.3461 - acc: 0.437 - 0s 156us/sample - loss: 2.3140 - acc: 0.3750\n",
      "Epoch 14/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.3473 - acc: 0.437 - 0s 171us/sample - loss: 2.3152 - acc: 0.3750\n",
      "Epoch 15/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.2796 - acc: 0.437 - 0s 156us/sample - loss: 2.2623 - acc: 0.3750\n",
      "Epoch 16/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.2253 - acc: 0.437 - 0s 171us/sample - loss: 2.2062 - acc: 0.3750\n",
      "Epoch 17/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.2102 - acc: 0.437 - 0s 187us/sample - loss: 2.1887 - acc: 0.3750\n",
      "Epoch 18/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.1643 - acc: 0.437 - 0s 203us/sample - loss: 2.1553 - acc: 0.3750\n",
      "Epoch 19/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.1270 - acc: 0.437 - 0s 187us/sample - loss: 2.1323 - acc: 0.3750\n",
      "Epoch 20/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.1148 - acc: 0.437 - 0s 187us/sample - loss: 2.0914 - acc: 0.3750\n",
      "Epoch 21/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.0646 - acc: 0.437 - 0s 156us/sample - loss: 2.0328 - acc: 0.3750\n",
      "Epoch 22/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.0291 - acc: 0.437 - 0s 156us/sample - loss: 2.0042 - acc: 0.3750\n",
      "Epoch 23/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.0167 - acc: 0.437 - 0s 156us/sample - loss: 2.0259 - acc: 0.3750\n",
      "Epoch 24/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.0007 - acc: 0.437 - 0s 156us/sample - loss: 1.9676 - acc: 0.3750\n",
      "Epoch 25/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.9964 - acc: 0.437 - 0s 140us/sample - loss: 2.0145 - acc: 0.3750\n",
      "Epoch 26/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.9103 - acc: 0.437 - 0s 125us/sample - loss: 1.9305 - acc: 0.3750\n",
      "Epoch 27/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.9584 - acc: 0.437 - 0s 171us/sample - loss: 1.9564 - acc: 0.3750\n",
      "Epoch 28/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.8657 - acc: 0.437 - 0s 171us/sample - loss: 1.8639 - acc: 0.3750\n",
      "Epoch 29/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.9238 - acc: 0.437 - 0s 202us/sample - loss: 1.8957 - acc: 0.3750\n",
      "Epoch 30/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.8805 - acc: 0.437 - 0s 187us/sample - loss: 1.8534 - acc: 0.3750\n",
      "Epoch 31/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.8996 - acc: 0.437 - 0s 187us/sample - loss: 1.8522 - acc: 0.3750\n",
      "Epoch 32/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.8851 - acc: 0.437 - 0s 187us/sample - loss: 1.8316 - acc: 0.3750\n",
      "Epoch 33/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.8370 - acc: 0.437 - 0s 172us/sample - loss: 1.8105 - acc: 0.3750\n",
      "Epoch 34/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.8289 - acc: 0.437 - 0s 171us/sample - loss: 1.7958 - acc: 0.3750\n",
      "Epoch 35/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.8099 - acc: 0.437 - 0s 171us/sample - loss: 1.7610 - acc: 0.3750\n",
      "Epoch 36/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.8099 - acc: 0.437 - 0s 187us/sample - loss: 1.7748 - acc: 0.3750\n",
      "Epoch 37/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.7509 - acc: 0.437 - 0s 171us/sample - loss: 1.7498 - acc: 0.3750\n",
      "Epoch 38/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.7832 - acc: 0.437 - 0s 187us/sample - loss: 1.7314 - acc: 0.3750\n",
      "Epoch 39/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.7795 - acc: 0.437 - 0s 140us/sample - loss: 1.7399 - acc: 0.3906\n",
      "Epoch 40/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.7593 - acc: 0.437 - 0s 171us/sample - loss: 1.7282 - acc: 0.3750\n",
      "Epoch 41/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.7721 - acc: 0.437 - 0s 156us/sample - loss: 1.7194 - acc: 0.3750\n",
      "Epoch 42/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.7235 - acc: 0.437 - 0s 156us/sample - loss: 1.6952 - acc: 0.3750\n",
      "Epoch 43/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.7163 - acc: 0.437 - 0s 203us/sample - loss: 1.6667 - acc: 0.3906\n",
      "Epoch 44/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.6737 - acc: 0.437 - 0s 140us/sample - loss: 1.6364 - acc: 0.3906\n",
      "Epoch 45/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.7153 - acc: 0.437 - 0s 140us/sample - loss: 1.6764 - acc: 0.3750\n",
      "Epoch 46/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.6791 - acc: 0.437 - 0s 156us/sample - loss: 1.6548 - acc: 0.3906\n",
      "Epoch 47/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.7258 - acc: 0.437 - 0s 140us/sample - loss: 1.6410 - acc: 0.3750\n",
      "Epoch 48/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.6733 - acc: 0.437 - 0s 140us/sample - loss: 1.6135 - acc: 0.3750\n",
      "Epoch 49/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.6750 - acc: 0.468 - 0s 156us/sample - loss: 1.6081 - acc: 0.4062\n",
      "Epoch 50/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.6620 - acc: 0.468 - 0s 140us/sample - loss: 1.5881 - acc: 0.4219\n",
      "Epoch 51/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.6286 - acc: 0.500 - 0s 156us/sample - loss: 1.5721 - acc: 0.4531\n",
      "Epoch 52/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.6568 - acc: 0.468 - 0s 140us/sample - loss: 1.6056 - acc: 0.4062\n",
      "Epoch 53/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.6021 - acc: 0.468 - 0s 140us/sample - loss: 1.5441 - acc: 0.4375\n",
      "Epoch 54/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.6169 - acc: 0.437 - 0s 171us/sample - loss: 1.5521 - acc: 0.3906\n",
      "Epoch 55/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.6165 - acc: 0.468 - 0s 140us/sample - loss: 1.5510 - acc: 0.4219\n",
      "Epoch 56/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.6128 - acc: 0.468 - 0s 156us/sample - loss: 1.5487 - acc: 0.4219\n",
      "Epoch 57/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.5493 - acc: 0.500 - 0s 156us/sample - loss: 1.5044 - acc: 0.4375\n",
      "Epoch 58/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.5496 - acc: 0.500 - 0s 140us/sample - loss: 1.4840 - acc: 0.4688\n",
      "Epoch 59/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.5456 - acc: 0.468 - 0s 140us/sample - loss: 1.4805 - acc: 0.4688\n",
      "Epoch 60/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.5198 - acc: 0.468 - 0s 156us/sample - loss: 1.4788 - acc: 0.4531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.5667 - acc: 0.437 - 0s 125us/sample - loss: 1.4797 - acc: 0.4688\n",
      "Epoch 62/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.5387 - acc: 0.468 - 0s 156us/sample - loss: 1.4803 - acc: 0.4844\n",
      "Epoch 63/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.4826 - acc: 0.468 - 0s 171us/sample - loss: 1.4343 - acc: 0.4531\n",
      "Epoch 64/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.4653 - acc: 0.468 - 0s 140us/sample - loss: 1.4203 - acc: 0.4844\n",
      "Epoch 65/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.4581 - acc: 0.500 - 0s 140us/sample - loss: 1.4025 - acc: 0.5000\n",
      "Epoch 66/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.4562 - acc: 0.500 - 0s 125us/sample - loss: 1.4104 - acc: 0.4688\n",
      "Epoch 67/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.4536 - acc: 0.468 - 0s 140us/sample - loss: 1.3711 - acc: 0.5000\n",
      "Epoch 68/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.4265 - acc: 0.500 - 0s 171us/sample - loss: 1.3820 - acc: 0.5000\n",
      "Epoch 69/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.4023 - acc: 0.500 - 0s 156us/sample - loss: 1.3478 - acc: 0.4844\n",
      "Epoch 70/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.4166 - acc: 0.500 - 0s 140us/sample - loss: 1.3441 - acc: 0.5312\n",
      "Epoch 71/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.3831 - acc: 0.500 - 0s 125us/sample - loss: 1.3466 - acc: 0.5000\n",
      "Epoch 72/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.3876 - acc: 0.500 - 0s 156us/sample - loss: 1.3143 - acc: 0.5000\n",
      "Epoch 73/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.3933 - acc: 0.500 - 0s 156us/sample - loss: 1.3180 - acc: 0.5000\n",
      "Epoch 74/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.4134 - acc: 0.468 - 0s 171us/sample - loss: 1.3532 - acc: 0.4844\n",
      "Epoch 75/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.3342 - acc: 0.500 - 0s 156us/sample - loss: 1.2984 - acc: 0.5000\n",
      "Epoch 76/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.3804 - acc: 0.500 - 0s 125us/sample - loss: 1.3235 - acc: 0.5156\n",
      "Epoch 77/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.3475 - acc: 0.500 - 0s 140us/sample - loss: 1.2937 - acc: 0.4844\n",
      "Epoch 78/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.3330 - acc: 0.500 - 0s 140us/sample - loss: 1.2720 - acc: 0.5312\n",
      "Epoch 79/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.3096 - acc: 0.500 - 0s 171us/sample - loss: 1.2441 - acc: 0.5312\n",
      "Epoch 80/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.3674 - acc: 0.468 - 0s 156us/sample - loss: 1.2905 - acc: 0.5156\n",
      "Epoch 81/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.3111 - acc: 0.500 - 0s 156us/sample - loss: 1.2834 - acc: 0.5156\n",
      "Epoch 82/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.3024 - acc: 0.468 - 0s 140us/sample - loss: 1.2182 - acc: 0.5469\n",
      "Epoch 83/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.2411 - acc: 0.562 - 0s 140us/sample - loss: 1.2094 - acc: 0.5625\n",
      "Epoch 84/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.3238 - acc: 0.593 - 0s 140us/sample - loss: 1.2535 - acc: 0.6250\n",
      "Epoch 85/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.2459 - acc: 0.593 - 0s 171us/sample - loss: 1.1853 - acc: 0.6094\n",
      "Epoch 86/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.2289 - acc: 0.531 - 0s 171us/sample - loss: 1.1981 - acc: 0.5625\n",
      "Epoch 87/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.2717 - acc: 0.531 - 0s 156us/sample - loss: 1.2103 - acc: 0.6094\n",
      "Epoch 88/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.2230 - acc: 0.500 - 0s 125us/sample - loss: 1.1704 - acc: 0.5469\n",
      "Epoch 89/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.1906 - acc: 0.562 - 0s 140us/sample - loss: 1.1684 - acc: 0.5625\n",
      "Epoch 90/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.1705 - acc: 0.625 - 0s 171us/sample - loss: 1.1289 - acc: 0.6094\n",
      "Epoch 91/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.1693 - acc: 0.562 - 0s 140us/sample - loss: 1.1490 - acc: 0.5625\n",
      "Epoch 92/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.1971 - acc: 0.593 - 0s 140us/sample - loss: 1.1092 - acc: 0.6250\n",
      "Epoch 93/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.1979 - acc: 0.562 - 0s 140us/sample - loss: 1.1340 - acc: 0.6094\n",
      "Epoch 94/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.2061 - acc: 0.593 - 0s 140us/sample - loss: 1.1538 - acc: 0.6094\n",
      "Epoch 95/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.1589 - acc: 0.593 - 0s 156us/sample - loss: 1.1223 - acc: 0.6094\n",
      "Epoch 96/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.2208 - acc: 0.531 - 0s 171us/sample - loss: 1.1670 - acc: 0.5781\n",
      "Epoch 97/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.0801 - acc: 0.687 - 0s 171us/sample - loss: 1.0772 - acc: 0.6719\n",
      "Epoch 98/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.0826 - acc: 0.687 - 0s 140us/sample - loss: 1.0462 - acc: 0.6406\n",
      "Epoch 99/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.1434 - acc: 0.625 - 0s 125us/sample - loss: 1.1147 - acc: 0.6406\n",
      "Epoch 100/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.0476 - acc: 0.687 - 0s 171us/sample - loss: 1.0361 - acc: 0.6562\n",
      "Epoch 101/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.0383 - acc: 0.781 - 0s 156us/sample - loss: 0.9930 - acc: 0.7500\n",
      "Epoch 102/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.0819 - acc: 0.687 - 0s 156us/sample - loss: 0.9937 - acc: 0.7031\n",
      "Epoch 103/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.1238 - acc: 0.625 - 0s 156us/sample - loss: 1.0524 - acc: 0.6406\n",
      "Epoch 104/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.0236 - acc: 0.718 - 0s 140us/sample - loss: 0.9993 - acc: 0.7188\n",
      "Epoch 105/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.0711 - acc: 0.718 - 0s 156us/sample - loss: 1.0454 - acc: 0.6719\n",
      "Epoch 106/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.0713 - acc: 0.687 - 0s 156us/sample - loss: 1.0425 - acc: 0.7031\n",
      "Epoch 107/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.9745 - acc: 0.750 - 0s 156us/sample - loss: 0.9692 - acc: 0.7344\n",
      "Epoch 108/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.9915 - acc: 0.687 - 0s 140us/sample - loss: 0.9738 - acc: 0.7344\n",
      "Epoch 109/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.0334 - acc: 0.718 - 0s 156us/sample - loss: 0.9750 - acc: 0.7500\n",
      "Epoch 110/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.9580 - acc: 0.718 - 0s 140us/sample - loss: 0.9619 - acc: 0.7188\n",
      "Epoch 111/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.9535 - acc: 0.781 - 0s 156us/sample - loss: 0.9215 - acc: 0.7812\n",
      "Epoch 112/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.9440 - acc: 0.687 - 0s 156us/sample - loss: 0.9523 - acc: 0.7031\n",
      "Epoch 113/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.9574 - acc: 0.750 - 0s 156us/sample - loss: 0.9467 - acc: 0.7500\n",
      "Epoch 114/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.9238 - acc: 0.750 - 0s 156us/sample - loss: 0.8946 - acc: 0.7812\n",
      "Epoch 115/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.8988 - acc: 0.843 - 0s 156us/sample - loss: 0.8904 - acc: 0.7969\n",
      "Epoch 116/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.9327 - acc: 0.812 - 0s 156us/sample - loss: 0.8943 - acc: 0.8125\n",
      "Epoch 117/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.8878 - acc: 0.812 - 0s 140us/sample - loss: 0.8732 - acc: 0.8594\n",
      "Epoch 118/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.8898 - acc: 0.843 - 0s 156us/sample - loss: 0.8548 - acc: 0.8750\n",
      "Epoch 119/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.9007 - acc: 0.812 - 0s 140us/sample - loss: 0.9201 - acc: 0.7812\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - ETA: 0s - loss: 0.8451 - acc: 0.906 - 0s 140us/sample - loss: 0.8513 - acc: 0.8438\n",
      "Epoch 121/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.8866 - acc: 0.843 - 0s 156us/sample - loss: 0.8454 - acc: 0.8125\n",
      "Epoch 122/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.9060 - acc: 0.875 - 0s 140us/sample - loss: 0.8513 - acc: 0.8594\n",
      "Epoch 123/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.8512 - acc: 0.875 - 0s 156us/sample - loss: 0.8216 - acc: 0.8438\n",
      "Epoch 124/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.8286 - acc: 0.875 - 0s 140us/sample - loss: 0.8519 - acc: 0.8594\n",
      "Epoch 125/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.8410 - acc: 0.843 - 0s 156us/sample - loss: 0.8163 - acc: 0.8750\n",
      "Epoch 126/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.8914 - acc: 0.812 - 0s 140us/sample - loss: 0.8137 - acc: 0.8750\n",
      "Epoch 127/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.8899 - acc: 0.812 - 0s 156us/sample - loss: 0.8104 - acc: 0.8438\n",
      "Epoch 128/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.8033 - acc: 0.875 - 0s 156us/sample - loss: 0.7705 - acc: 0.9062\n",
      "Epoch 129/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.8029 - acc: 0.843 - 0s 156us/sample - loss: 0.7335 - acc: 0.9062\n",
      "Epoch 130/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.8461 - acc: 0.812 - 0s 140us/sample - loss: 0.8002 - acc: 0.8438\n",
      "Epoch 131/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.8187 - acc: 0.875 - 0s 140us/sample - loss: 0.7702 - acc: 0.8750\n",
      "Epoch 132/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.8285 - acc: 0.812 - 0s 156us/sample - loss: 0.7606 - acc: 0.8906\n",
      "Epoch 133/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.7674 - acc: 0.875 - 0s 156us/sample - loss: 0.7212 - acc: 0.9375\n",
      "Epoch 134/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.7684 - acc: 0.906 - 0s 140us/sample - loss: 0.7289 - acc: 0.9219\n",
      "Epoch 135/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.8220 - acc: 0.906 - 0s 140us/sample - loss: 0.7798 - acc: 0.8750\n",
      "Epoch 136/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.8159 - acc: 0.875 - 0s 140us/sample - loss: 0.7544 - acc: 0.8906\n",
      "Epoch 137/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.7854 - acc: 0.875 - 0s 171us/sample - loss: 0.7410 - acc: 0.9062\n",
      "Epoch 138/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.7660 - acc: 0.875 - 0s 156us/sample - loss: 0.6896 - acc: 0.9219\n",
      "Epoch 139/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.7838 - acc: 0.906 - 0s 156us/sample - loss: 0.7250 - acc: 0.9219\n",
      "Epoch 140/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.7193 - acc: 0.937 - 0s 140us/sample - loss: 0.6782 - acc: 0.9531\n",
      "Epoch 141/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.7410 - acc: 0.906 - 0s 125us/sample - loss: 0.6828 - acc: 0.9375\n",
      "Epoch 142/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.6953 - acc: 0.906 - 0s 156us/sample - loss: 0.6693 - acc: 0.9062\n",
      "Epoch 143/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.6851 - acc: 0.937 - 0s 156us/sample - loss: 0.6611 - acc: 0.9219\n",
      "Epoch 144/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.7033 - acc: 0.937 - 0s 156us/sample - loss: 0.6521 - acc: 0.9531\n",
      "Epoch 145/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.7305 - acc: 0.937 - 0s 156us/sample - loss: 0.6832 - acc: 0.9531\n",
      "Epoch 146/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.7946 - acc: 0.875 - 0s 125us/sample - loss: 0.7219 - acc: 0.8906\n",
      "Epoch 147/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.6787 - acc: 0.906 - 0s 171us/sample - loss: 0.6320 - acc: 0.9375\n",
      "Epoch 148/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.6094 - acc: 0.968 - 0s 156us/sample - loss: 0.6406 - acc: 0.8750\n",
      "Epoch 149/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.6339 - acc: 0.937 - 0s 140us/sample - loss: 0.5895 - acc: 0.9688\n",
      "Epoch 150/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.6664 - acc: 0.937 - 0s 156us/sample - loss: 0.6214 - acc: 0.9531\n",
      "Epoch 151/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.6394 - acc: 0.937 - 0s 125us/sample - loss: 0.5857 - acc: 0.9688\n",
      "Epoch 152/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.6243 - acc: 0.937 - 0s 156us/sample - loss: 0.6251 - acc: 0.9219\n",
      "Epoch 153/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.6282 - acc: 0.937 - 0s 156us/sample - loss: 0.6264 - acc: 0.9375\n",
      "Epoch 154/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5969 - acc: 0.937 - 0s 156us/sample - loss: 0.5471 - acc: 0.9688\n",
      "Epoch 155/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.6448 - acc: 0.937 - 0s 140us/sample - loss: 0.6134 - acc: 0.9375\n",
      "Epoch 156/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.6185 - acc: 0.906 - 0s 140us/sample - loss: 0.5987 - acc: 0.9219\n",
      "Epoch 157/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5825 - acc: 0.968 - 0s 140us/sample - loss: 0.5324 - acc: 0.9688\n",
      "Epoch 158/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.6000 - acc: 0.906 - 0s 156us/sample - loss: 0.5521 - acc: 0.9375\n",
      "Epoch 159/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.6080 - acc: 0.906 - 0s 156us/sample - loss: 0.5747 - acc: 0.9219\n",
      "Epoch 160/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.6162 - acc: 0.937 - 0s 156us/sample - loss: 0.5335 - acc: 0.9688\n",
      "Epoch 161/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5655 - acc: 0.968 - 0s 140us/sample - loss: 0.5406 - acc: 0.9531\n",
      "Epoch 162/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5793 - acc: 0.968 - 0s 140us/sample - loss: 0.5567 - acc: 0.9375\n",
      "Epoch 163/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.6238 - acc: 0.906 - 0s 140us/sample - loss: 0.5459 - acc: 0.9375\n",
      "Epoch 164/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5329 - acc: 0.937 - 0s 156us/sample - loss: 0.5131 - acc: 0.9531\n",
      "Epoch 165/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5836 - acc: 0.937 - 0s 140us/sample - loss: 0.5237 - acc: 0.9688\n",
      "Epoch 166/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5872 - acc: 0.937 - 0s 140us/sample - loss: 0.5504 - acc: 0.9531\n",
      "Epoch 167/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5659 - acc: 0.906 - 0s 140us/sample - loss: 0.5156 - acc: 0.9375\n",
      "Epoch 168/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5229 - acc: 0.937 - 0s 140us/sample - loss: 0.4678 - acc: 0.9688\n",
      "Epoch 169/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4942 - acc: 0.937 - 0s 156us/sample - loss: 0.4679 - acc: 0.9375\n",
      "Epoch 170/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5182 - acc: 0.937 - 0s 140us/sample - loss: 0.4875 - acc: 0.9375\n",
      "Epoch 171/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5855 - acc: 0.875 - 0s 140us/sample - loss: 0.5162 - acc: 0.9375\n",
      "Epoch 172/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5785 - acc: 0.875 - 0s 140us/sample - loss: 0.5087 - acc: 0.9062\n",
      "Epoch 173/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5002 - acc: 0.968 - 0s 156us/sample - loss: 0.4640 - acc: 0.9531\n",
      "Epoch 174/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5815 - acc: 0.875 - 0s 140us/sample - loss: 0.5143 - acc: 0.9375\n",
      "Epoch 175/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4752 - acc: 0.968 - 0s 156us/sample - loss: 0.4737 - acc: 0.9531\n",
      "Epoch 176/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5355 - acc: 0.875 - 0s 156us/sample - loss: 0.4856 - acc: 0.9062\n",
      "Epoch 177/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5018 - acc: 0.968 - 0s 171us/sample - loss: 0.4454 - acc: 0.9688\n",
      "Epoch 178/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4729 - acc: 0.968 - 0s 156us/sample - loss: 0.4362 - acc: 0.9531\n",
      "Epoch 179/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - ETA: 0s - loss: 0.4817 - acc: 0.937 - 0s 140us/sample - loss: 0.4544 - acc: 0.9531\n",
      "Epoch 180/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4845 - acc: 0.937 - 0s 140us/sample - loss: 0.4386 - acc: 0.9531\n",
      "Epoch 181/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4890 - acc: 0.937 - 0s 156us/sample - loss: 0.4463 - acc: 0.9688\n",
      "Epoch 182/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4399 - acc: 0.937 - 0s 125us/sample - loss: 0.4347 - acc: 0.9375\n",
      "Epoch 183/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4955 - acc: 0.937 - 0s 125us/sample - loss: 0.4482 - acc: 0.9531\n",
      "Epoch 184/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4895 - acc: 0.937 - 0s 156us/sample - loss: 0.4371 - acc: 0.9688\n",
      "Epoch 185/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4356 - acc: 0.968 - 0s 156us/sample - loss: 0.4148 - acc: 0.9688\n",
      "Epoch 186/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4179 - acc: 0.968 - 0s 140us/sample - loss: 0.3794 - acc: 0.9844\n",
      "Epoch 187/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4244 - acc: 0.968 - 0s 125us/sample - loss: 0.4075 - acc: 0.9688\n",
      "Epoch 188/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4016 - acc: 0.968 - 0s 156us/sample - loss: 0.3682 - acc: 0.9688\n",
      "Epoch 189/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4239 - acc: 0.937 - 0s 156us/sample - loss: 0.3953 - acc: 0.9531\n",
      "Epoch 190/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3905 - acc: 0.968 - 0s 156us/sample - loss: 0.3734 - acc: 0.9844\n",
      "Epoch 191/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4668 - acc: 0.968 - 0s 156us/sample - loss: 0.4251 - acc: 0.9688\n",
      "Epoch 192/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4605 - acc: 0.937 - 0s 125us/sample - loss: 0.4021 - acc: 0.9531\n",
      "Epoch 193/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3954 - acc: 0.968 - 0s 140us/sample - loss: 0.3691 - acc: 0.9844\n",
      "Epoch 194/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4867 - acc: 0.968 - 0s 140us/sample - loss: 0.4339 - acc: 0.9531\n",
      "Epoch 195/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4235 - acc: 0.968 - 0s 156us/sample - loss: 0.3898 - acc: 0.9688\n",
      "Epoch 196/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4072 - acc: 0.968 - 0s 140us/sample - loss: 0.4131 - acc: 0.9375\n",
      "Epoch 197/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3887 - acc: 0.968 - 0s 140us/sample - loss: 0.3596 - acc: 0.9688\n",
      "Epoch 198/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3739 - acc: 0.968 - 0s 125us/sample - loss: 0.3536 - acc: 0.9844\n",
      "Epoch 199/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3811 - acc: 0.968 - 0s 140us/sample - loss: 0.3575 - acc: 0.9688\n",
      "Epoch 200/200\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4025 - acc: 0.968 - 0s 172us/sample - loss: 0.3514 - acc: 0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa.core.policies.keras_policy:Done fitting keras policy model\n",
      "INFO:rasa_core.agent:Model directory models/current/dialogue\\core exists and contains old model files. All files will be overwritten.\n",
      "INFO:rasa_core.agent:Persisted model to 'D:\\Yogesh\\ToDos\\Teaching\\TeachingDataScience\\Jupyter\\models\\current\\dialogue\\core'\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from rasa_core.policies import FallbackPolicy, KerasPolicy, MemoizationPolicy, MappingPolicy\n",
    "from rasa_core.agent import Agent\n",
    "\n",
    "# this will catch predictions the model isn't very certain about\n",
    "# there is a threshold for the NLU predictions as well as the action predictions\n",
    "fallback = FallbackPolicy(fallback_action_name=\"utter_unclear\",\n",
    "                          core_threshold=0.2,\n",
    "                          nlu_threshold=0.1)\n",
    "\n",
    "# agent = Agent('domain.yml', policies=[MemoizationPolicy(), KerasPolicy(), fallback])\n",
    "\n",
    "agent = Agent('config/domain.yml', policies = [MemoizationPolicy(max_history=2), KerasPolicy(validation_split=0.2,epochs=200),MappingPolicy()])\n",
    "# loop = asyncio.get_event_loop() # https://github.com/RasaHQ/rasa/issues/3649\n",
    "# training_data = loop.run_until_complete(agent.load_data('data/stories.md'))\n",
    "training_data = await agent.load_data('data/stories.md') # https://forum.rasa.com/t/call-agent-train-occurs-typeerror-coroutine-object-is-not-iterable/10135/10\n",
    "# loading our neatly defined training dialogues\n",
    "# training_data = agent.load_data('data/stories.md')\n",
    "\n",
    "agent.train(training_data)\n",
    "# FOLLOWING WAY OF giving arguments is depreacted, instead, give these params as arguments to KerasPolicy\n",
    "# agent.train(\n",
    "#     training_data,\n",
    "#     validation_split=0.0,\n",
    "#     epochs=200\n",
    "# )\n",
    "\n",
    "agent.persist('models/current/dialogue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4911z6y-5rD"
   },
   "source": [
    "## Running: Talk to your Bot\n",
    "\n",
    "So we have the chatbot ready. It’s time to chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way is to run following command in shell (windows cmd)\n",
    "- activate the environment,\n",
    "- come to directory where actions.py is and then run\n",
    "- **python -m rasa_core.run -d models/current/dialogue -u models/current/nlu --endpoints endpoints.yml**\n",
    "\n",
    "Or else do programmatically like below\n",
    "\n",
    "Both approaches expect rasa core sdk server running in a separate window, else **python -m rasa_core_sdk.endpoint --actions actions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nE4coPam5hry",
    "outputId": "c8ec135b-882b-4e9e-a955-f3e184177817"
   },
   "outputs": [],
   "source": [
    "# #Starting the Bot\n",
    "\n",
    "# from rasa_core.agent import Agent\n",
    "# agent = Agent.load('models/current/dialogue', interpreter=model_directory)\n",
    "import IPython\n",
    "from IPython.display import clear_output\n",
    "from rasa_core.agent import Agent\n",
    "from rasa_core.interpreter import NaturalLanguageInterpreter\n",
    "# from rasa_core.utils import EndpointConfig\n",
    "from rasa.utils.endpoints import EndpointConfig\n",
    "\n",
    "import time\n",
    "\n",
    "def load_assistant():\n",
    "    messages = [\"Hi! you can chat in this window. Type 'stop' to end the conversation.\"]\n",
    "    model_dir = 'models/nlu/current' # or model_directory defined earlier\n",
    "    interpreter = NaturalLanguageInterpreter.create(model_dir)\n",
    "    endpoint = EndpointConfig('http://localhost:5055/webhook')\n",
    "    agent = Agent.load('models/current/dialogue', interpreter=interpreter, action_endpoint = endpoint)\n",
    "\n",
    "    print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "    while True:\n",
    "        a = input()\n",
    "        if a == 'stop':\n",
    "            break\n",
    "        responses = agent.handle_text(a)\n",
    "        for response in responses:\n",
    "            print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "DDVLzhAT5yrP",
    "outputId": "aee3fc83-df97-42b4-c7e0-c8929f76337c"
   },
   "outputs": [],
   "source": [
    "load_assistant()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "enJNkbvB54y1"
   },
   "source": [
    "## What Next?\n",
    "\n",
    "- Try to use different pipelines in Rasa Core, explore more Policies, fine-tune those models, \n",
    "- Check out what other features CricAPI provides, etc.\n",
    "- Other APIs\n",
    "- Slot filling\n",
    "- Different languages (Hindi bot?)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "include_colab_link": true,
   "name": "Conversational_Chatbot.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:conda-rasa] *",
   "language": "python",
   "name": "conda-env-conda-rasa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
